\documentclass[twoside,11pt]{article}
\usepackage{jmlr2e}            % <- uncomment for JMLR submission
%\usepackage{jmlr2e-stripped}    % <- uncomment for arXiv version

\usepackage{amsmath,amsfonts}
\usepackage{url}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}

\input{latex_front}
\input{latex_macros}

\usepackage{caption}
\captionsetup{format=hang}

\includecomment{arxiv}\excludecomment{kdd}

% See http://www.jmlr.org/format/sample.tex

% Heading arguments are {volume}{year}{pages}{submitted}{published}{author-full-names}
\jmlrheading{19}{2018}{1-78}{11/17}{5/18}{17-716}{Elaine Angelino, Nicholas Larus-Stone, Daniel Alabi, Margo Seltzer, and Cynthia Rudin}

% Short headings should be running head and authors last names
\ShortHeadings{Learning Certifiably Optimal Rule Lists}{Angelino, Larus-Stone, Alabi, Seltzer, and Rudin}
\firstpageno{1}

\begin{document}

\title{Learning Certifiably Optimal Rule Lists for Categorical Data}

\author{\name Elaine Angelino \email elaine@eecs.berkeley.edu \\
        \addr Department of Electrical Engineering and Computer Sciences\\
        University of California, Berkeley,
        Berkeley, CA 94720
        \AND
        \name Nicholas Larus-Stone \email nlarusstone@alumni.harvard.edu \\
        \name Daniel Alabi \email alabid@g.harvard.edu \\
        \name Margo Seltzer \email margo@eecs.harvard.edu \\
        \addr School of Engineering and Applied Sciences\\
        Harvard University,
        Cambridge, MA 02138
        \AND
        \name Cynthia Rudin$^*$ \email cynthia@cs.duke.edu \\
        \addr Department of Computer Science and
        Department of Electrical and Computer Engineering\\
        Duke University,
        Durham, NC 27708}

\editor{Maya Gupta\\ $^*$To whom correspondence should be addressed.}
%\footnote{}

\maketitle

\begin{abstract}%   <- trailing '%' for backward compatibility of .sty file
\input{sections/abstract}
\end{abstract}

\begin{keywords}
    rule lists, decision trees, optimization, interpretable models, criminal justice applications
\end{keywords}

\section{Introduction}

As machine learning continues to gain prominence in socially-important decision-making,
the interpretability of predictive models remains a crucial problem.
%
Our goal is to build models that are highly predictive, transparent, and easily understood by humans.
%
We use rule lists, also known as decision lists, to achieve this goal.
%
Rule lists are predictive models composed of if-then statements;
these models are interpretable because the rules provide a reason for each prediction~(Figure~\ref{fig:rule-list}).

Constructing rule lists, or more generally, decision trees, has been a challenge for more than
30 years; most approaches use greedy splitting techniques~\citep{Rivest87,Breiman84,Quinlan93}.
%
Recent approaches use Bayesian analysis, either to find a locally optimal solution~\citep{Chipman:1998jh} or to explore the search space~\citep{LethamRuMcMa15, YangRuSe16}.
%
These approaches achieve high accuracy while also managing to run reasonably quickly.
%
However, despite the apparent accuracy of the rule lists generated by these algorithms,
there is no way to determine either if the generated rule list is optimal or how close it is to optimal,
where optimality is defined with respect to minimization of a regularized loss function.

\begin{arxiv}
\begin{figure}[t!]
\begin{algorithmic}
\State \bif $(age=18-20) \band (sex=male)$ \bthen $yes$
\State \belif $(age=21-23)	 \band (priors=2-3)$ \bthen $yes$
\State \belif $(priors>3)$ \bthen $yes$
\State \belse $no$
\end{algorithmic}
\caption{An example rule list that predicts two-year recidivism
for the ProPublica data set, found by CORELS.
}
\label{fig:rule-list}
\end{figure}
\end{arxiv}

Optimality is important, because there are societal implications for a lack of optimality.
%
Consider the ProPublica article on the Correctional Offender Management Profiling for Alternative Sanctions
(COMPAS) recidivism prediction tool~\citep{LarsonMaKiAn16}.
%
It highlights a case where a black box, proprietary predictive model is being used for recidivism prediction.
%
The authors hypothesize that the COMPAS scores are racially biased,
but since the model is not transparent, no one (outside of the creators of COMPAS)
can determine the reason or extent of the bias~\citep{LarsonMaKiAn16},
nor can anyone determine the reason for any particular prediction.
%
By using COMPAS, users implicitly assumed that a transparent model
would not be sufficiently accurate for recidivism prediction,
\ie they assumed that a black box model would provide better accuracy.
%
We wondered whether there was indeed no transparent and sufficiently accurate model.
%
Answering this question requires solving a computationally hard problem.
%
Namely, we would like to both find a transparent model that is optimal
within a particular pre-determined class of models
and produce a certificate of its optimality, with respect to the regularized empirical risk.
%
This would enable one to say, for this problem and model class,
with certainty and before resorting to black box methods,
whether there exists a transparent~model.
%
While there may be differences between training and test performance,
finding the simplest model with optimal training performance is prescribed by
statistical learning theory.

To that end, we consider the class of rule lists assembled from pre-mined frequent itemsets
and search for an optimal rule list that minimizes a regularized risk function,~$R$.
%
This is a hard discrete optimization problem.
%
Brute force solutions that minimize~$R$ are computationally prohibitive
due to the exponential number of possible rule lists.
%
However, this is a worst case bound that is not realized in practical settings.
%
For realistic cases, it is possible to solve fairly large cases of this problem to optimality,
with the careful use of algorithms, data structures, and implementation techniques.

\begin{kdd}
\begin{figure}[b!]
\vspace{-3mm}
\begin{algorithmic}
\normalsize
\State \bif $(age=23-25) \band (priors=2-3)$ \bthen $yes$
\State \belif $(age=18-20)$ \bthen $yes$
\State \belif $(sex=male) \band (age=21-22)$ \bthen $yes$
\State \belif $(priors>3)$ \bthen $yes$
\State \belse $no$
\end{algorithmic}
\vspace{-3mm}
\caption{An example rule list that predicts two-year recidivism
for the ProPublica data set, found by CORELS.
}
\label{fig:rule-list}
\end{figure}
\end{kdd}

We develop specialized tools from the fields of discrete optimization and artificial intelligence.
%
Specifically, we introduce a special branch-and bound algorithm, called
Certifiably Optimal RulE ListS (CORELS), that provides the optimal solution
according to the training objective, along with a certificate of optimality.
%
The certificate of optimality means that we can investigate how close other models
(\eg models provided by greedy algorithms) are to optimal.

\begin{arxiv}
Within its branch-and-bound procedure, CORELS maintains a lower bound on the
minimum value of~$R$ that each incomplete rule list can achieve.
%
This allows CORELS to prune an incomplete rule list (and every possible extension)
if the bound is larger than the error of the best rule list that it has already evaluated.
%
The use of careful bounding techniques leads to massive pruning of
the search space of potential rule lists.
%
The algorithm continues to consider incomplete and complete rule lists until it has either
examined or eliminated every rule list from consideration.
%
Thus, CORELS terminates with the optimal rule list and a certificate of optimality.
\end{arxiv}

The efficiency of CORELS depends on how much of the search space our bounds
allow us to prune; we seek a tight lower bound on~$R$.
%
The bound we maintain throughout execution is a maximum of several bounds
that come in three categories.
%
The first category of bounds are those intrinsic to the rules themselves.
%
This category includes bounds stating that each rule must capture sufficient data;
if not, the rule list is provably non-optimal.
%
The second type of bound compares a lower bound on the value of~$R$
to that of the current best solution.
%
This allows us to exclude parts of the search space that could never be better
than our current solution.
%
Finally, our last type of bound is based on comparing incomplete rule lists that
capture the same data and allows us to pursue only the most accurate option.
%
This last class of bounds is especially important---without our use of a novel
\textit{symmetry-aware map}, we are unable to solve most problems of reasonable scale.
%
This symmetry-aware map keeps track of the best accuracy
over all observed permutations of a given incomplete rule list.

We keep track of these bounds using a modified \emph{prefix tree},
a data structure also known as a trie.
%
Each node in the prefix tree represents an individual rule;
thus, each path in the tree represents a rule list such that
the final node in the path contains metrics about that rule list.
%
This tree structure, together with a search policy and sometimes a queue,
enables a variety of strategies, including breadth-first,
best-first, and stochastic search.
%
In particular, we can design different best-first strategies
by customizing how we order elements in a priority queue.
%
In addition, we are able to limit the number of nodes in the trie
and thereby enable tuning of space-time tradeoffs in a robust manner.
%
This trie structure is a useful way of organizing the generation
and evaluation of rule lists.

\begin{arxiv}
We evaluated CORELS on a number of publicly available data sets.
%
Our metric of success was 10-fold cross-validated prediction accuracy on a subset of the data.
%
These data sets involve hundreds of rules and thousands of observations.
%
CORELS is generally able to find an optimal rule list in a matter of seconds
and certify its optimality within about 10 minutes.
%
We show that we are able to achieve better or similar out-of-sample accuracy on these
data sets compared to the popular greedy algorithms, CART and C4.5.
\end{arxiv}

CORELS targets large (not massive) problems,
where interpretability and certifiable optimality are important.
%
We illustrate the efficacy of our approach using (1)~the ProPublica COMPAS data set~\citep{LarsonMaKiAn16}, for the problem of two-year recidivism prediction,
and (2)~stop-and-frisk data sets from the
\begin{kdd}
New York Civil Liberties Union (NYCLU)~\citep{nyclu:2014},
\end{kdd}
\begin{arxiv}
NYPD~\citep{nypd} and the NYCLU~\citep{nyclu:2014},
\end{arxiv}
to predict whether a weapon will be found
on a stopped individual who is frisked or searched.
%
On these data, we produce certifiably optimal, interpretable rule lists that achieve
the same accuracy as approaches such as random forests.
%
This calls into question the need for use of a proprietary,
black box algorithm for recidivism prediction.

Our work overlaps with the thesis of~\citet{Larus-Stone17}.
%
We have also written a
\begin{kdd}
long version of this report that includes proofs to all
bounds in~\S\ref{sec:framework}, additional bounds and empirical results,
and further implementation and data processing details~\citep{AngelinoLaAlSeRu17}. \\

Our code is at \textbf{\url{https://github.com/nlarusstone/corels}}.
\end{kdd}
\begin{arxiv}
preliminary conference version of this article~\citep{AngelinoLaAlSeRu17-kdd}, and a report
highlighting systems optimizations of our implementation~\citep{Larus-Stone18-sysml}; the latter includes
additional empirical measurements not presented here. \\

Our code is at \textbf{\url{https://github.com/nlarusstone/corels}},
where we provide the C++ implementation we used in our experiments~(\S\ref{sec:experiments}).
% Python and R wrappers?
%
\citet{corels-website} have also created an interactive web interface at
\textbf{\url{https://corels.eecs.harvard.edu}}, where a user can upload data and
run CORELS from a browser.
\end{arxiv}

\section{Related Work}

Since every rule list is a decision tree and every decision tree can be expressed as an equivalent rule list, the problem we are solving is a version of the ``optimal decision tree'' problem, though regularization changes the nature of the problem (as shown through our bounds). The optimal decision tree problem is computationally hard, though since the late 1990's, there has been research on building optimal decision trees using optimization techniques~\citep{Bennett96optimaldecision,dobkininduction,FarhangfarGZ08}. A particularly interesting paper along these lines is that of \citet{NijssenFromont2010}, who created a ``bottom-up'' way to form optimal decision trees. Their method performs an expensive search step, mining all possible leaves (rather than all possible rules), and uses those leaves to form trees. Their method can lead to memory problems, but it is possible that these memory issues can be mitigated using the theorems in this paper.\footnote{There is no public version of their code for distribution as of this writing.} None of these methods used the tight bounds and data structures of CORELS.

Because the optimal decision tree problem is hard, there are a huge number of algorithms such as CART \citep{Breiman84} and C4.5 \citep{Quinlan93} that do not perform exploration of the search space beyond greedy splitting. Similarly, there are decision list and associative classification methods that construct rule lists iteratively in a greedy way
\citep{Rivest87,Liu98,Li01,Yin03,Sokolova03,Marchand05,Vanhoof10,RudinLeMa13}.
Some exploration of the search space is done by Bayesian decision tree methods~\citep{Dension:1998hl,Chipman:2002hc,Chipman10} and Bayesian rule-based methods \citep{LethamRuMcMa15,YangRuSe16}. The space of trees of a given depth is much larger than the space of
rule lists of that same depth, and the trees within the Bayesian tree algorithms
are grown in a top-down greedy way. Because of this, authors of Bayesian tree algorithms have noted that their MCMC chains tend to reach only locally optimal solutions.
The RIPPER algorithm \citep{ripper} is similar to the Bayesian tree methods in that it grows, prunes, and then locally optimizes.
%
The space of rule lists is smaller than that of trees, and has simpler structure.
%
Consequently, Bayesian rule list algorithms tend to be more successful at
escaping local minima and can introduce methods of exploring the search space
that exploit this structure---these properties motivate our focus on lists.
%
That said, the tightest bounds for the Bayesian lists \citep[namely, those of][upon whose work we build]{YangRuSe16},
are not nearly as tight as those of CORELS.

Tight bounds, on the other hand, have been developed for the (immense) literature on building disjunctive normal form (DNF) models; a good example of this is the work of \citet{Rijnbeek10}.
%
For models of a given size, since the class of DNF's is a proper subset of decision lists, our framework can be restricted to learn optimal DNF's.
The field of DNF learning includes work from the fields of rule learning/induction \citep[\eg early algorithms by][]{Michalski1969,ClarkNiblett1989,Frank1998} and associative classification \citep{Vanhoof10}.
Most papers in these fields aim to carefully guide the search through the space of models. If we were to place a restriction on our code to learn DNF's, which would require restricting predictions within the list to the positive class only, we could potentially use methods from rule learning and associative classification to help order CORELS' queue, which would in turn help us eliminate parts of the search space more quickly.

Some of our bounds, including the minimum support bound
(\S\ref{sec:lb-support}, Theorem~\ref{thm:min-capture}),
come from \citet{RudinEr16}, who provide flexible mixed-integer programming (MIP)
formulations using the same objective as we use here;
MIP solvers in general cannot compete with the speed of CORELS.

CORELS depends on pre-mined rules, which we obtain here via enumeration.
The literature on association rule mining is huge, and any method for rule mining could be reasonably substituted.

CORELS' main use is for producing interpretable predictive models. There is a growing interest in interpretable (transparent, comprehensible) models because of their societal importance \citep[see][]{ruping2006learning,bratko1997machine,dawes1979robust,VellidoEtAl12,Giraud98,Holte93,Schmueli10,Huysmans11,Freitas14}. There are now regulations on algorithmic decision-making in the European Union on the ``right to an explanation'' \citep{Goodman2016EU} that would legally require interpretability of predictions. There is work in both the DNF literature \citep{Ruckert2008} and decision tree literature \citep{GarofalakisHyRaSh00} on building interpretable models. Interpretable models must be so sparse that they need to be heavily optimized; heuristics tend to produce either inaccurate or non-sparse models.

Interpretability has many meanings, and it is possible to extend the ideas in this work to other definitions of interpretability; these rule lists may have exotic constraints that help with ease-of-use. For example, Falling Rule Lists \citep{WangRu15} are constrained to have decreasing probabilities down the list, which makes it easier to assess whether an observation is in a high risk subgroup. In parallel to this paper, we have been working on an algorithm for Falling Rule Lists \citep{ChenRu18} with bounds similar to those presented here, but even CORELS' basic support bounds do not hold for the falling case, which is much more complicated. One advantage of the approach taken by \citet{ChenRu18} is that it can handle class imbalance by weighting the positive and negative classes differently; this extension is possible in CORELS but not addressed here.

The models produced by CORELS are predictive only; they cannot be used for policy-making because they are not causal models, they do not include the costs of true and false positives, nor the cost of gathering information. It is possible to adapt CORELS' framework for causal inference \citep{WangRu15CFRL}, dynamic treatment regimes \citep{ZhangEtAl15}, or cost-sensitive dynamic treatment regimes \citep{LakkarajuRu17} to help with policy design.  CORELS could potentially be adapted to handle these kinds of interesting problems.

\input{sections/framework}

\input{sections/bounds}

\input{sections/implementation-long}

\input{sections/experiments-long}

\input{sections/conclusion}

% Acknowledgements should go at the end, before appendices and references
\acks{E.A. conducted most of this work while supported by the Miller Institute for Basic Research
in Science, University of California, Berkeley, and hosted by Prof. M.I. Jordan at RISELab.
%
C.D.R. is supported in part by MIT-Lincoln Labs and the National Science Foundation under IIS-1053407.
%
E.A. would like to thank E.~Jonas, E.~Kohler, and S.~Tu for early implementation
guidance, A.~D'Amour for pointing out the work by~\citet{Goel16}, V.~Kanade, S.~McCurdy,
J.~Schleier-Smith and E.~Thewalt for helpful conversations, and members of RISELab,
SAIL, and the UC Berkeley Database Group for their support and feedback.
%
We thank H.~Yang and B.~Letham for sharing advice and code for processing data
and mining rules, B.~Coker for his critical advice on using the ProPublica COMPAS data set,
as well as V.~Kaxiras and A.~Saligrama for their recent contributions to our implementation
and for creating the CORELS website. We are very grateful to our editor and anonymous reviewers.
}

\vskip 0.2in

\renewcommand{\theHsection}{A\arabic{section}}
\appendix
%\renewcommand{\thesection}{\Alph{section}}
\input{sections/appendix-bounds}
\input{sections/appendix}

\bibliography{refs}

\end{document}
