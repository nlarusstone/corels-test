\documentclass[twoside,11pt]{article}
\usepackage{jmlr2e}            % <- uncomment for JMLR submission
%\usepackage{jmlr2e-stripped}    % <- uncomment for arXiv version

\usepackage{amsmath,amsfonts}
\usepackage{url}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}

\input{latex_front}
\input{latex_macros}

\usepackage{caption}
\captionsetup{format=hang}

\includecomment{arxiv}\excludecomment{kdd}

% See http://www.jmlr.org/format/sample.tex

% Heading arguments are {volume}{year}{pages}{submitted}{published}{author-full-names}
\jmlrheading{19}{2018}{1-78}{11/17}{5/18}{17-716}{Elaine Angelino, Nicholas Larus-Stone, Daniel Alabi, Margo Seltzer, and Cynthia Rudin}

% Short headings should be running head and authors last names
\ShortHeadings{Learning Certifiably Optimal Rule Lists}{Angelino, Larus-Stone, Alabi, Seltzer, and Rudin}
\firstpageno{1}

\begin{document}

\title{Learning Certifiably Optimal Rule Lists for Categorical Data}

\author{\name Elaine Angelino \email elaine@eecs.berkeley.edu \\
        \addr Department of Electrical Engineering and Computer Sciences\\
        University of California, Berkeley,
        Berkeley, CA 94720
        \AND
        \name Nicholas Larus-Stone \email nlarusstone@alumni.harvard.edu \\
        \name Daniel Alabi \email alabid@g.harvard.edu \\
        \name Margo Seltzer \email margo@eecs.harvard.edu \\
        \addr School of Engineering and Applied Sciences\\
        Harvard University,
        Cambridge, MA 02138
        \AND
        \name Cynthia Rudin$^*$ \email cynthia@cs.duke.edu \\
        \addr Department of Computer Science and
        Department of Electrical and Computer Engineering\\
        Duke University,
        Durham, NC 27708}

\editor{Maya Gupta\\ $^*$To whom correspondence should be addressed.}
%\footnote{}

\maketitle

\begin{abstract}%   <- trailing '%' for backward compatibility of .sty file
\input{sections/abstract}
\end{abstract}

\begin{keywords}
    rule lists, decision trees, optimization, interpretable models, criminal justice applications
\end{keywords}

\section{Introduction}

As machine learning continues to gain prominence in socially-important decision-making,
the interpretability of predictive models remains a crucial problem.
%
Our goal is to build models that are highly predictive, transparent, and easily understood by humans.
%
We use rule lists, also known as decision lists, to achieve this goal.
%
Rule lists are predictive models composed of if-then statements;
these models are interpretable because the rules provide a reason for each prediction~(Figure~\ref{fig:rule-list}).

Constructing rule lists, or more generally, decision trees, has been a challenge for more than
30 years; most approaches use greedy splitting techniques~\citep{Rivest87,Breiman84,Quinlan93}.
%
Recent approaches use Bayesian analysis, either to find a locally optimal solution~\citep{Chipman:1998jh} or to explore the search space~\citep{LethamRuMcMa15, YangRuSe16}.
%
These approaches achieve high accuracy while also managing to run reasonably quickly.
%
However, despite the apparent accuracy of the rule lists generated by these algorithms,
there is no way to determine either if the generated rule list is optimal or how close it is to optimal,
where optimality is defined with respect to minimization of a regularized loss function.

\begin{arxiv}
\begin{figure}[t!]
\begin{algorithmic}
\State \bif $(age=18-20) \band (sex=male)$ \bthen $yes$
\State \belif $(age=21-23)	 \band (priors=2-3)$ \bthen $yes$
\State \belif $(priors>3)$ \bthen $yes$
\State \belse $no$
\end{algorithmic}
\caption{An example rule list that predicts two-year recidivism
for the ProPublica data set, found by CORELS.
}
\label{fig:rule-list}
\end{figure}
\end{arxiv}

Optimality is important, because there are societal implications for a lack of optimality.
%
Consider the ProPublica article on the Correctional Offender Management Profiling for Alternative Sanctions
(COMPAS) recidivism prediction tool~\citep{LarsonMaKiAn16}.
%
It highlights a case where a black box, proprietary predictive model is being used for recidivism prediction.
%
The authors hypothesize that the COMPAS scores are racially biased,
but since the model is not transparent, no one (outside of the creators of COMPAS)
can determine the reason or extent of the bias~\citep{LarsonMaKiAn16},
nor can anyone determine the reason for any particular prediction.
%
By using COMPAS, users implicitly assumed that a transparent model
would not be sufficiently accurate for recidivism prediction,
\ie they assumed that a black box model would provide better accuracy.
%
We wondered whether there was indeed no transparent and sufficiently accurate model.
%
Answering this question requires solving a computationally hard problem.
%
Namely, we would like to both find a transparent model that is optimal
within a particular pre-determined class of models
and produce a certificate of its optimality, with respect to the regularized empirical risk.
%
This would enable one to say, for this problem and model class,
with certainty and before resorting to black box methods,
whether there exists a transparent~model.
%
While there may be differences between training and test performance,
finding the simplest model with optimal training performance is prescribed by
statistical learning theory.

To that end, we consider the class of rule lists assembled from pre-mined frequent itemsets
and search for an optimal rule list that minimizes a regularized risk function,~$R$.
%
This is a hard discrete optimization problem.
%
Brute force solutions that minimize~$R$ are computationally prohibitive
due to the exponential number of possible rule lists.
%
However, this is a worst case bound that is not realized in practical settings.
%
For realistic cases, it is possible to solve fairly large cases of this problem to optimality,
with the careful use of algorithms, data structures, and implementation techniques.

\begin{kdd}
\begin{figure}[b!]
\vspace{-3mm}
\begin{algorithmic}
\normalsize
\State \bif $(age=23-25) \band (priors=2-3)$ \bthen $yes$
\State \belif $(age=18-20)$ \bthen $yes$
\State \belif $(sex=male) \band (age=21-22)$ \bthen $yes$
\State \belif $(priors>3)$ \bthen $yes$
\State \belse $no$
\end{algorithmic}
\vspace{-3mm}
\caption{An example rule list that predicts two-year recidivism
for the ProPublica data set, found by CORELS.
}
\label{fig:rule-list}
\end{figure}
\end{kdd}

We develop specialized tools from the fields of discrete optimization and artificial intelligence.
%
Specifically, we introduce a special branch-and bound algorithm, called
Certifiably Optimal RulE ListS (CORELS), that provides the optimal solution
according to the training objective, along with a certificate of optimality.
%
The certificate of optimality means that we can investigate how close other models
(\eg models provided by greedy algorithms) are to optimal.

\begin{arxiv}
Within its branch-and-bound procedure, CORELS maintains a lower bound on the
minimum value of~$R$ that each incomplete rule list can achieve.
%
This allows CORELS to prune an incomplete rule list (and every possible extension)
if the bound is larger than the error of the best rule list that it has already evaluated.
%
The use of careful bounding techniques leads to massive pruning of
the search space of potential rule lists.
%
The algorithm continues to consider incomplete and complete rule lists until it has either
examined or eliminated every rule list from consideration.
%
Thus, CORELS terminates with the optimal rule list and a certificate of optimality.
\end{arxiv}

The efficiency of CORELS depends on how much of the search space our bounds
allow us to prune; we seek a tight lower bound on~$R$.
%
The bound we maintain throughout execution is a maximum of several bounds
that come in three categories.
%
The first category of bounds are those intrinsic to the rules themselves.
%
This category includes bounds stating that each rule must capture sufficient data;
if not, the rule list is provably non-optimal.
%
The second type of bound compares a lower bound on the value of~$R$
to that of the current best solution.
%
This allows us to exclude parts of the search space that could never be better
than our current solution.
%
Finally, our last type of bound is based on comparing incomplete rule lists that
capture the same data and allows us to pursue only the most accurate option.
%
This last class of bounds is especially important---without our use of a novel
\textit{symmetry-aware map}, we are unable to solve most problems of reasonable scale.
%
This symmetry-aware map keeps track of the best accuracy
over all observed permutations of a given incomplete rule list.

We keep track of these bounds using a modified \emph{prefix tree},
a data structure also known as a trie.
%
Each node in the prefix tree represents an individual rule;
thus, each path in the tree represents a rule list such that
the final node in the path contains metrics about that rule list.
%
This tree structure, together with a search policy and sometimes a queue,
enables a variety of strategies, including breadth-first,
best-first, and stochastic search.
%
In particular, we can design different best-first strategies
by customizing how we order elements in a priority queue.
%
In addition, we are able to limit the number of nodes in the trie
and thereby enable tuning of space-time tradeoffs in a robust manner.
%
This trie structure is a useful way of organizing the generation
and evaluation of rule lists.

\begin{arxiv}
We evaluated CORELS on a number of publicly available data sets.
%
Our metric of success was 10-fold cross-validated prediction accuracy on a subset of the data.
%
These data sets involve hundreds of rules and thousands of observations.
%
CORELS is generally able to find an optimal rule list in a matter of seconds
and certify its optimality within about 10 minutes.
%
We show that we are able to achieve better or similar out-of-sample accuracy on these
data sets compared to the popular greedy algorithms, CART and C4.5.
\end{arxiv}

CORELS targets large (not massive) problems,
where interpretability and certifiable optimality are important.
%
We illustrate the efficacy of our approach using (1)~the ProPublica COMPAS data set~\citep{LarsonMaKiAn16}, for the problem of two-year recidivism prediction,
and (2)~stop-and-frisk data sets from the
\begin{kdd}
New York Civil Liberties Union (NYCLU)~\citep{nyclu:2014},
\end{kdd}
\begin{arxiv}
NYPD~\citep{nypd} and the NYCLU~\citep{nyclu:2014},
\end{arxiv}
to predict whether a weapon will be found
on a stopped individual who is frisked or searched.
%
On these data, we produce certifiably optimal, interpretable rule lists that achieve
the same accuracy as approaches such as random forests.
%
This calls into question the need for use of a proprietary,
black box algorithm for recidivism prediction.

Our work overlaps with the thesis of~\citet{Larus-Stone17}.
%
We have also written a
\begin{kdd}
long version of this report that includes proofs to all
bounds in~\S\ref{sec:framework}, additional bounds and empirical results,
and further implementation and data processing details~\citep{AngelinoLaAlSeRu17}. \\

Our code is at \textbf{\url{https://github.com/nlarusstone/corels}}.
\end{kdd}
\begin{arxiv}
preliminary conference version of this article~\citep{AngelinoLaAlSeRu17-kdd}, and a report
highlighting systems optimizations of our implementation~\citep{Larus-Stone18-sysml}; the latter includes
additional empirical measurements not presented here. \\

Our code is at \textbf{\url{https://github.com/nlarusstone/corels}},
where we provide the C++ implementation we used in our experiments~(\S\ref{sec:experiments}).
% Python and R wrappers?
%
\citet{corels-website} have also created an interactive web interface at
\textbf{\url{https://corels.eecs.harvard.edu}}, where a user can upload data and
run CORELS from a browser.
\end{arxiv}

\section{Related Work}

Since every rule list is a decision tree and every decision tree can be expressed as an equivalent rule list, the problem we are solving is a version of the ``optimal decision tree'' problem, though regularization changes the nature of the problem (as shown through our bounds). The optimal decision tree problem is computationally hard, though since the late 1990's, there has been research on building optimal decision trees using optimization techniques~\citep{Bennett96optimaldecision,dobkininduction,FarhangfarGZ08}. A particularly interesting paper along these lines is that of \citet{NijssenFromont2010}, who created a ``bottom-up'' way to form optimal decision trees. Their method performs an expensive search step, mining all possible leaves (rather than all possible rules), and uses those leaves to form trees. Their method can lead to memory problems, but it is possible that these memory issues can be mitigated using the theorems in this paper.\footnote{There is no public version of their code for distribution as of this writing.} None of these methods used the tight bounds and data structures of CORELS.

Because the optimal decision tree problem is hard, there are a huge number of algorithms such as CART \citep{Breiman84} and C4.5 \citep{Quinlan93} that do not perform exploration of the search space beyond greedy splitting. Similarly, there are decision list and associative classification methods that construct rule lists iteratively in a greedy way
\citep{Rivest87,Liu98,Li01,Yin03,Sokolova03,Marchand05,Vanhoof10,RudinLeMa13}.
Some exploration of the search space is done by Bayesian decision tree methods~\citep{Dension:1998hl,Chipman:2002hc,Chipman10} and Bayesian rule-based methods \citep{LethamRuMcMa15,YangRuSe16}. The space of trees of a given depth is much larger than the space of
rule lists of that same depth, and the trees within the Bayesian tree algorithms
are grown in a top-down greedy way. Because of this, authors of Bayesian tree algorithms have noted that their MCMC chains tend to reach only locally optimal solutions.
The RIPPER algorithm \citep{ripper} is similar to the Bayesian tree methods in that it grows, prunes, and then locally optimizes.
%
The space of rule lists is smaller than that of trees, and has simpler structure.
%
Consequently, Bayesian rule list algorithms tend to be more successful at
escaping local minima and can introduce methods of exploring the search space
that exploit this structure---these properties motivate our focus on lists.
%
That said, the tightest bounds for the Bayesian lists \citep[namely, those of][upon whose work we build]{YangRuSe16},
are not nearly as tight as those of CORELS.

Tight bounds, on the other hand, have been developed for the (immense) literature on building disjunctive normal form (DNF) models; a good example of this is the work of \citet{Rijnbeek10}.
%
For models of a given size, since the class of DNF's is a proper subset of decision lists, our framework can be restricted to learn optimal DNF's.
The field of DNF learning includes work from the fields of rule learning/induction \citep[\eg early algorithms by][]{Michalski1969,ClarkNiblett1989,Frank1998} and associative classification \citep{Vanhoof10}.
Most papers in these fields aim to carefully guide the search through the space of models. If we were to place a restriction on our code to learn DNF's, which would require restricting predictions within the list to the positive class only, we could potentially use methods from rule learning and associative classification to help order CORELS' queue, which would in turn help us eliminate parts of the search space more quickly.

Some of our bounds, including the minimum support bound
(\S\ref{sec:lb-support}, Theorem~\ref{thm:min-capture}),
come from \citet{RudinEr16}, who provide flexible mixed-integer programming (MIP)
formulations using the same objective as we use here;
MIP solvers in general cannot compete with the speed of CORELS.

CORELS depends on pre-mined rules, which we obtain here via enumeration.
The literature on association rule mining is huge, and any method for rule mining could be reasonably substituted.

CORELS' main use is for producing interpretable predictive models. There is a growing interest in interpretable (transparent, comprehensible) models because of their societal importance \citep[see][]{ruping2006learning,bratko1997machine,dawes1979robust,VellidoEtAl12,Giraud98,Holte93,Schmueli10,Huysmans11,Freitas14}. There are now regulations on algorithmic decision-making in the European Union on the ``right to an explanation'' \citep{Goodman2016EU} that would legally require interpretability of predictions. There is work in both the DNF literature \citep{Ruckert2008} and decision tree literature \citep{GarofalakisHyRaSh00} on building interpretable models. Interpretable models must be so sparse that they need to be heavily optimized; heuristics tend to produce either inaccurate or non-sparse models.

Interpretability has many meanings, and it is possible to extend the ideas in this work to other definitions of interpretability; these rule lists may have exotic constraints that help with ease-of-use. For example, Falling Rule Lists \citep{WangRu15} are constrained to have decreasing probabilities down the list, which makes it easier to assess whether an observation is in a high risk subgroup. In parallel to this paper, we have been working on an algorithm for Falling Rule Lists \citep{ChenRu18} with bounds similar to those presented here, but even CORELS' basic support bounds do not hold for the falling case, which is much more complicated. One advantage of the approach taken by \citet{ChenRu18} is that it can handle class imbalance by weighting the positive and negative classes differently; this extension is possible in CORELS but not addressed here.

The models produced by CORELS are predictive only; they cannot be used for policy-making because they are not causal models, they do not include the costs of true and false positives, nor the cost of gathering information. It is possible to adapt CORELS' framework for causal inference \citep{WangRu15CFRL}, dynamic treatment regimes \citep{ZhangEtAl15}, or cost-sensitive dynamic treatment regimes \citep{LakkarajuRu17} to help with policy design.  CORELS could potentially be adapted to handle these kinds of interesting problems.

\section{Learning Optimal Rule Lists}
\label{sec:framework}

\begin{arxiv}
In this section, we present our framework for learning certifiably optimal rule lists.
%
First, we define our setting and useful notation~(\S\ref{sec:setup})
and then the objective function we seek to minimize~(\S\ref{sec:objective}).
%
Next, we describe the principal structure of our optimization algorithm~(\S\ref{sec:optimization}), which depends on a hierarchically
structured objective lower bound~(\S\ref{sec:hierarchical}).
%
We then derive a series of additional bounds that we incorporate into our
algorithm, because they enable aggressive pruning of our state space.
\end{arxiv}

\subsection{Notation}
\label{sec:setup}

\begin{arxiv}
We restrict our setting to binary classification,
where rule lists are Boolean functions;
this framework is straightforward to generalize to multi-class classification.
\end{arxiv}
\begin{kdd}
We restrict our setting to binary classification.
\end{kdd}
%
Let~${\{(x_n, y_n)\}_{n=1}^N}$ denote training data,
where ${x_n \in \{0, 1\}^J}$ are binary features and ${y_n \in \{0, 1\}}$ are labels.
%
Let~${\x = \{x_n\}_{n=1}^N}$ and~${\y = \{y_n\}_{n=1}^N}$,
and let~${x_{n,j}}$ denote the $j$-th feature of~$x_n$.

A rule list ${\RL = (r_1, r_2, \dots, r_K, r_0)}$ of length~${K \ge 0}$
is a ${(K+1)}$-tuple consisting of~$K$ distinct association rules,
${r_k = p_k \rightarrow q_k}$, for ${k = 1, \dots, K}$,
followed by a default rule~$r_0$.
%
\begin{arxiv}
Figure~\ref{fig:rule-list-symbols} illustrates
a rule list, ${\RL =}$ ${(r_1, r_2, r_3, r_0)}$,
which for clarity, we sometimes call a $K$-rule list.
\end{arxiv}
\begin{kdd}
Figure~\ref{fig:rule-list} illustrates a 3-rule list,
${\RL =}$ ${(r_1, r_2, r_3, r_0)}$.
\end{kdd}
%
An association rule~${r = p \rightarrow q}$ is an implication
corresponding to the conditional statement, ``if~$p$, then~$q$.''
%
In our setting, an antecedent~$p$ is a Boolean assertion that
evaluates to either true or false for each datum~$x_n$,
and a consequent~$q$ is a label prediction.
%
For example, ${(x_{n, 1} = 0) \wedge (x_{n, 3} = 1) \rightarrow}$ ${(y_n = 1)}$
is an association rule.
%
%The number of conditions in an antecedent is its cardinality;
%the antecedent in the previous example has a cardinality of two.
%
The final default rule~$r_0$ in a rule list can be thought of
as a
\begin{arxiv}
special
\end{arxiv}
association rule~${p_0 \rightarrow q_0}$
whose antecedent~$p_0$ simply asserts true.

\begin{arxiv}
\begin{figure}[t!]
\small
\begin{subfigure}{0.67\textwidth}
\begin{algorithmic}
\State \bif $(age=18-20) \band (sex=male)$ \bthen $yes$
\State \belif $(age=21-23)	 \band (priors=2-3)$ \bthen $yes$
\State \belif $(priors>3)$ \bthen $yes$
\State \belse $no$
\end{algorithmic}
\end{subfigure}
\hfill
\begin{subfigure}{0.32\textwidth}
\begin{algorithmic}
\State \bif $p_1$ \bthen $q_1$
\State \belif $p_2$ \bthen $q_2$
\State \belif $p_3$ \bthen $q_3$
\State \belse $q_0$
\end{algorithmic}
\end{subfigure}
\caption{The rule list ${\RL = (r_1, r_2, r_3, r_0)}$.
Each rule is of the form ${r_k = p_k \rightarrow q_k}$,
for all ${k = 0, \dots, 3}$.
We can also express this rule list as ${\RL = (\Prefix, \Labels, \Default, K)}$,
where ${\Prefix = (p_1, p_2, p_3)}$, ${\Labels = (1, 1, 1, 1)}$,
${\Default = 0}$, and ${K=3}$.
This is the same 3-rule list as in Figure~\ref{fig:rule-list},
that predicts two-year recidivism for the ProPublica data set.
}
\label{fig:rule-list-symbols}
\end{figure}
\end{arxiv}

Let ${\RL = (r_1, r_2, \dots, r_K, r_0)}$ be a
\begin{arxiv}
$K$-rule list,
\end{arxiv}
\begin{kdd}
rule list,
\end{kdd}
where ${r_k = p_k \rightarrow q_k}$ for each ${k = 0, \dots, K}$.
%
We introduce a useful alternate rule list representation:
${\RL = (\Prefix, \Labels, \Default, K)}$,
where we define ${\Prefix = (p_1, \dots, p_K)}$ to be $\RL$'s prefix,
${\Labels = (q_1, \dots, q_K) \in \{0, 1\}^K}$~gives
the label predictions associated with~$\Prefix$,
and ${\Default \in \{0, 1\}}$ is the default label prediction.
%
For
\begin{arxiv}
example, for
\end{arxiv}
the rule list in Figure~\ref{fig:rule-list},
we would write ${\RL = (\Prefix, \Labels, \Default, K)}$,
where ${\Prefix = (p_1, p_2, p_3)}$, ${\Labels = (1, 1, 1)}$,
${\Default = 0}$, and ${K=3}$.
%
Note that ${((), (), q_0, 0)}$ is a well-defined rule list with an empty prefix;
it is completely defined by a single default rule.

Let ${\Prefix = (p_1, \dots, p_k, \dots, p_K)}$ be an antecedent list,
then for any ${k \le K}$, we define ${\Prefix^k =}$ ${(p_1, \dots, p_k)}$
to be the $k$-prefix of~$\Prefix$.
%
For any such $k$-prefix~$\Prefix^k$,
we say that~$\Prefix$ starts with~$\Prefix^k$.
%
For any given space of rule lists,
we define~$\StartsWith(\Prefix)$ to be the set of
all rule lists whose prefixes start with~$\Prefix$:
\begin{align}
\StartsWith(\Prefix) =
\{(\Prefix', \Labels', \Default', K') : \Prefix' \textnormal{ starts with } \Prefix \}.
\label{eq:starts-with}
\end{align}
%We also say that an antecedent list~$\Prefix$ contains another
%antecedent list~$\Prefix'$ if the antecedents in~$\Prefix'$ correspond to
% a contiguous subsequence of antecedents anywhere in~$\Prefix$.
%
If ${\Prefix = (p_1, \dots, p_K)}$ and ${\Prefix' = (p_1, \dots, p_K, p_{K+1})}$
are two prefixes such that~$\Prefix'$ starts with~$\Prefix$ and extends it by
a single antecedent, we say that~$\Prefix$ is the parent of~$\Prefix'$
and that~$\Prefix'$ is a child of~$\Prefix$.

A rule list~$\RL$ classifies datum~$x_n$ by providing the label prediction~$q_k$
of the first rule~$r_k$ whose antecedent~$p_k$ is true for~$x_n$.
%
We say that an antecedent~$p_k$ of antecedent list~$\Prefix$ captures~$x_n$
in the context of~$\Prefix$ if~$p_k$ is the first antecedent in~$\Prefix$ that
evaluates to true for~$x_n$.
%
\begin{arxiv}
We also say that a
\end{arxiv}
\begin{kdd}
A
\end{kdd}
prefix captures those data captured by its antecedents;
for a rule list~${\RL = (\Prefix, \Labels, \Default, K)}$,
data not captured by the prefix~$\Prefix$
are classified according to the default label prediction~$\Default$.

Let~$\beta$ be a set of antecedents.
%
We define~${\Cap(x_n, \beta) = 1}$ if an antecedent in~$\beta$
captures datum~$x_n$, and~0 otherwise.
%
For example, let~$\Prefix$ and~$\Prefix'$ be prefixes such that~$\Prefix'$ starts
with~$\Prefix$, then~$\Prefix'$ captures all the data that~$\Prefix$ captures:
\begin{arxiv}
\begin{align*}
\{x_n: \Cap(x_n, \Prefix)\} \subseteq \{x_n: \Cap(x_n, \Prefix')\}.
%\label{eq:cap-subset}
\end{align*}
\end{arxiv}
\begin{kdd}
${\{x_n: \Cap(x_n, \Prefix)\} \subseteq \{x_n: \Cap(x_n, \Prefix')\}}$.
\end{kdd}
%We also define ${\Cap(\x, \beta) = \{\Cap(x_n, \beta)\}_{n=1}^N} \in \{0, 1\}^N$
%to be~$\beta$'s captures vector.

Now let~$\Prefix$ be an ordered list of antecedents,
and let~$\beta$ be a subset of antecedents in~$\Prefix$.
%
Let us define~${\Cap(x_n, \beta \given \Prefix) = 1}$ if~$\beta$
captures datum~$x_n$ in the context of~$\Prefix$,
\ie if the first antecedent in~$\Prefix$ that evaluates to true for~$x_n$
is an antecedent in~$\beta$, and~0 otherwise.
%
Thus, ${\Cap(x_n, \beta \given \Prefix) = 1}$ only if ${\Cap(x_n, \beta) = 1}$;
${\Cap(x_n, \beta \given \Prefix) = 0}$ either if ${\Cap(x_n, \beta) = 0}$,
or if ${\Cap(x_n, \beta) = 1}$ but there is an antecedent~$\alpha$ in~$\Prefix$,
preceding all antecedents in~$\beta$, such that ${\Cap(x_n, \alpha) = 1}$.
%
For example, if ${\Prefix = (p_1, \dots, p_k, \dots, p_K)}$ is a prefix, then
\begin{align*}
\Cap(x_n, p_k \given \Prefix) =
  \left(\bigwedge_{k'=1}^{k - 1} \neg\, \Cap(x_n, p_{k'}) \right)
  \wedge \Cap(x_n, p_k)
\end{align*}
indicates whether antecedent~$p_k$ captures datum~$x_n$ in the context of~$\Prefix$.
%
Now, define ${\Supp(\beta, \x)}$ to be the normalized support of~$\beta$,
\begin{align}
\Supp(\beta, \x) = \frac{1}{N} \sum_{n=1}^N \Cap(x_n, \beta),
\label{eq:support}
\end{align}
and similarly define~${\Supp(\beta, \x \given \Prefix)}$
to be the normalized support of~$\beta$ in the context of~$\Prefix$,
\begin{align}
\Supp(\beta, \x \given \Prefix) = \frac{1}{N} \sum_{n=1}^N \Cap(x_n, \beta \given \Prefix),
\label{eq:support-context}
\end{align}

Next, we address how empirical data constrains rule lists.
%
Given training data~${(\x, \y)}$,
an antecedent list ${\Prefix = (p_1, \dots, p_K)}$
implies a rule list ${\RL = (\Prefix, \Labels, \Default, K)}$
with prefix~$\Prefix$, where the label predictions
${\Labels = (q_1, \dots, q_K)}$ and~$\Default$ are empirically set
to minimize the number of misclassification errors made by
the rule list on the training data.
%
Thus for~${1 \le k \le K}$, label prediction~$q_k$ corresponds to the
majority label of data captured by antecedent~$p_k$ in the context of~$\Prefix$,
and the default~$\Default$ corresponds to the majority label of data
not captured by~$\Prefix$.
%
In the remainder of our presentation, whenever we refer to a rule list with a
particular prefix, we implicitly assume these empirically determined label predictions.

Our method is technically an associative classification method since it
leverages pre-mined rules.

\subsection{Objective Function}
\label{sec:objective}

\begin{arxiv}
We define
\end{arxiv}
\begin{kdd}
Define
\end{kdd}
a simple objective function for a rule list ${\RL = (\Prefix, \Labels, \Default, K)}$:
\begin{align}
\Obj(\RL, \x, \y) = \Loss(\RL, \x, \y) + \Reg K.
\label{eq:objective}
\end{align}
This objective function is a regularized empirical risk;
it consists of a loss~$\Loss(\RL, \x, \y)$, measuring misclassification error,
and a regularization term that penalizes longer rule lists.
%
$\Loss(\RL, \x, \y)$~is the fraction of training data whose labels are
incorrectly predicted by~$\RL$.
%
In our setting, the regularization parameter~${\Reg \ge 0}$ is a small constant;
\eg ${\Reg = 0.01}$ can be thought of as adding a penalty equivalent to misclassifying~$1\%$
of data when increasing a rule list's length
\begin{arxiv}
by one association rule.
\end{arxiv}
\begin{kdd}
by~one.
\end{kdd}
%
%As noted in~\S\ref{sec:setup}, a prefix~$\Prefix$ and training data together
%fully specify a rule list~${\RL = (\Prefix, \Labels, \Default, K)}$,
%thus let us define~${\Obj(\Prefix, \x, \y) \equiv \Obj(\RL, \x, \y)}$.

\subsection{Optimization Framework}
\label{sec:optimization}

Our objective has structure amenable to global optimization via a branch-and-bound framework.
%
In particular, we make a series of important observations, each of which translates into
a useful bound, and that together interact to eliminate large parts of the search~space.
%
We discuss these in depth in what follows:
%
\begin{itemize}
\item Lower bounds on a prefix also hold for every extension of that prefix.
(\S\ref{sec:hierarchical}, Theorem~\ref{thm:bound})

\item If a rule list is not accurate enough with respect to its length,
we can prune all extensions of it.
(\S\ref{sec:hierarchical}, Lemma~\ref{lemma:lookahead})

\item We can calculate \emph{a priori} an upper bound on the maximum length
of an optimal rule list.
(\S\ref{sec:ub-prefix-length}, Theorem~\ref{thm:ub-prefix-specific})

\item Each rule in an optimal rule list must have support that is sufficiently large.
%(Otherwise it would not be in an optimal rule list.)
%
This allows us to construct rule lists from frequent itemsets,
while preserving the guarantee that we can find a globally optimal
rule list from pre-mined rules.
(\S\ref{sec:lb-support}, Theorem~\ref{thm:min-capture})

\item Each rule in an optimal rule list must predict accurately.
%
In particular, the number of observations predicted correctly
by each rule in an optimal rule list must be above a threshold.
(\S\ref{sec:lb-support}, Theorem~\ref{thm:min-capture-correct})

\item We need only consider the optimal permutation of antecedents in a prefix;
we can omit all other permutations.
(\S\ref{sec:equivalent}, Theorem~\ref{thm:equivalent} and Corollary~\ref{thm:permutation})

\item  If multiple observations have identical features and opposite labels,
we know that any model will make mistakes.
%
In particular, the number of mistakes on these observations will be at least
the number of observations with the minority label.
(\S\ref{sec:identical}, Theorem~\ref{thm:identical})
\end{itemize}
\begin{kdd}
We present additional theorems and all proofs in~\citep{AngelinoLaAlSeRu17}.
\end{kdd}

\subsection{Hierarchical Objective Lower Bound}
\label{sec:hierarchical}

We can decompose the misclassification error
\begin{arxiv}
in~\eqref{eq:objective}
\end{arxiv}
into two contributions corresponding to the prefix and the default rule:
\begin{align*}
\Loss(\RL, \x, \y) %= \Loss(\Prefix, r_q, \Default, \x, \y)
\equiv \Loss_p(\Prefix, \Labels, \x, \y) + \Loss_0(\Prefix, \Default, \x, \y),
\end{align*}
where ${\Prefix = (p_1, \dots, p_K)}$ and ${\Labels = (q_1, \dots, q_K)}$;
\begin{align*}
\Loss_p(\Prefix, \Labels, \x, \y) =
\frac{1}{N} \sum_{n=1}^N \sum_{k=1}^K \Cap(x_n, p_k \given \Prefix) \wedge \one [ q_k \neq y_n ]
%\label{eq:loss}
\end{align*}
is the fraction of data captured and misclassified by the prefix, and
\begin{align*}
\Loss_0(\Prefix, \Default, \x, \y) =
\frac{1}{N} \sum_{n=1}^N \neg\, \Cap(x_n, \Prefix) \wedge \one [ \Default \neq y_n ]
\end{align*}
is the fraction of data not captured by the prefix and misclassified by the default rule.
%
Eliminating the latter error term gives a lower bound~$b(\Prefix, \x, \y)$ on the objective,
\begin{align}
b(\Prefix, \x, \y) \equiv \Loss_p(\Prefix, \Labels, \x, \y) + \Reg K \le \Obj(\RL, \x, \y),
\label{eq:lower-bound}
\end{align}
where we have suppressed the lower bound's dependence on label predictions~$\Labels$
because they are fully determined, given~${(\Prefix, \x, \y)}$.
%
Furthermore,
\begin{arxiv}
as we state next in Theorem~\ref{thm:bound},
\end{arxiv}
$b(\Prefix, \x, \y)$ gives a lower bound on the objective of
\emph{any} rule list whose prefix starts with~$\Prefix$.

\begin{theorem}[Hierarchical objective lower bound]
\begin{arxiv}
Define~${b(\Prefix, \x, \y)}$
\end{arxiv}
\begin{kdd}
Define~${b(\Prefix, \x, \y) = \Loss_p(\Prefix, \Labels, \x, \y) + \Reg K}$,
\end{kdd}
as in~\eqref{eq:lower-bound}.
%
Also, define $\StartsWith(\Prefix)$ to be the set of all rule lists
whose prefixes starts with~$\Prefix$, as in~\eqref{eq:starts-with}.
%
Let ${\RL = }$ ${(\Prefix, \Labels, \Default, K)}$ be a rule list
with prefix~$\Prefix$, and let
${\RL' = (\Prefix', \Labels', \Default', K')}$ $\in \StartsWith(\Prefix)$
be any rule list such that its prefix~$\Prefix'$ starts with~$\Prefix$
and ${K' \ge K}$, then ${b(\Prefix, \x, \y) \le}$ ${\Obj(\RL', \x, \y)}$.
\label{thm:bound}
\end{theorem}

\begin{arxiv}
\begin{proof}
Let ${\Prefix = (p_1, \dots, p_K)}$ and ${\Labels = (q_1, \dots, q_K)}$;
let ${\Prefix' = (p_1, \dots, p_K, p_{K+1}, \dots, p_{K'})}$
and ${\Labels' = (q_1, \dots, q_K, q_{K+1}, \dots, q_{K'})}$.
%
Notice that~$\Prefix'$ yields the same mistakes as~$\Prefix$,
and possibly additional mistakes:
\begin{align}
&\Loss_p(\Prefix', \Labels', \x, \y)
= \frac{1}{N} \sum_{n=1}^N  \sum_{k=1}^{K'} \Cap(x_n, p_k \given \Prefix') \wedge \one [ q_k \neq y_n ] \nn \\
&= \frac{1}{N} \sum_{n=1}^N \left( \sum_{k=1}^K \Cap(x_n, p_k \given \Prefix) \wedge \one [ q_k \neq y_n ]
+ \sum_{k=K+1}^{K'} \Cap(x_n, p_k \given \Prefix') \wedge \one [ q_k \neq y_n ] \right) \nn \\
&=\Loss_p(\Prefix, \Labels, \x, \y)
+ \frac{1}{N} \sum_{n=1}^N \sum_{k=K+1}^{K'} \Cap(x_n, p_k \given \Prefix') \wedge \one [ q_k \neq y_n ]
\ge \Loss_p(\Prefix, \Labels, \x, \y),
\label{eq:prefix-loss}
\end{align}
where in the second equality we have used the fact that
${\Cap(x_n, p_k \given \Prefix') = \Cap(x_n, p_k \given \Prefix)}$
for~${1 \le k \le K}$.
%
It follows that
\begin{align}
b(\Prefix, \x, \y) &= \Loss_p(\Prefix, \Labels, \x, \y) + \Reg K \nn \\
&\le  \Loss_p(\Prefix', \Labels', \x, \y) + \Reg K' = b(\Prefix', \x, \y)
\le \Obj(\RL', \x, \y).
\label{eq:prefix-lb}
\end{align}
\end{proof}
\end{arxiv}

To generalize, consider a sequence of prefixes such that each prefix
starts with all previous prefixes in the sequence.
%
It follows that the corresponding sequence of objective lower bounds
increases monotonically.
%
This is precisely the structure required and exploited by branch-and-bound,
illustrated in Algorithm~\ref{alg:branch-and-bound}.

\begin{algorithm}[t!]
\caption{Branch-and-bound for learning rule lists.}
\label{alg:branch-and-bound}
\begin{algorithmic}
\normalsize
\State \textbf{Input:} Objective function $\Obj(\RL, \x, \y)$,
objective lower bound ${b(\Prefix, \x, \y)}$,
set of antecedents ${\RuleSet = \{s_m\}_{m=1}^M}$,
training data $(\x, \y) = {\{(x_n, y_n)\}_{n=1}^N}$,
initial best known rule list~$\InitialRL$ with objective
${\InitialObj = \Obj(\InitialRL, \x, \y)}$;
$\InitialRL$ could be obtained as output from another (approximate) algorithm,
otherwise, $(\InitialRL, \InitialObj) = (\text{null}, 1)$ provide reasonable default values
\State \textbf{Output:} Provably optimal rule list~$\OptimalRL$ with minimum objective~$\OptimalObj$ \\

\State $(\CurrentRL, \CurrentObj) \gets (\InitialRL, \InitialObj)$ \Comment{Initialize best rule list and objective}
\State $Q \gets $ queue$(\,[\,(\,)\,]\,)$ \Comment{Initialize queue with empty prefix}
\While {$Q$ not empty} \Comment{Stop when queue is empty}
	\State $\Prefix \gets Q$.pop(\,) \Comment{Remove prefix~$\Prefix$ from the queue}
	\begin{arxiv}
	\State $\RL \gets (\Prefix, \Labels, \Default, K)$ \Comment{Set label predictions~$\Labels$ and~$\Default$ to minimize training error}
	\end{arxiv}
	\If {$b(\Prefix, \x, \y) < \CurrentObj$} \Comment{\textbf{Bound}: Apply Theorem~\ref{thm:bound}}
        \State $\Obj \gets \Obj(\RL, \x, \y)$ \Comment{Compute objective of~$\Prefix$'s rule list~$\RL$}
        \If {$\Obj < \CurrentObj$} \Comment{Update best rule list and objective}
            \State $(\CurrentRL, \CurrentObj) \gets (\RL, \Obj)$
        \EndIf
        \For {$s$ in $\RuleSet$} \Comment{\textbf{Branch}: Enqueue~$\Prefix$'s children}
            \If {$s$ not in $\Prefix$}
                \State $Q$.push$(\,(\Prefix, s)\,)$
            \EndIf
        \EndFor
    \EndIf
\EndWhile
\State $(\OptimalRL, \OptimalObj) \gets (\CurrentRL, \CurrentObj)$ \Comment{Identify provably optimal solution}
\end{algorithmic}
\end{algorithm}

Specifically, the objective lower bound in Theorem~\ref{thm:bound}
enables us to prune the state space hierarchically.
%
While executing branch-and-bound, we keep track of the current best (smallest)
objective~$\CurrentObj$, thus it is a dynamic, monotonically decreasing quantity.
%
If we encounter a prefix~$\Prefix$ with lower bound
${b(\Prefix, \x, \y) \ge \CurrentObj}$,
then by Theorem~\ref{thm:bound}, we do not need to consider \emph{any}
rule list~${\RL' \in \StartsWith(\Prefix)}$ whose prefix~$\Prefix'$ starts with~$\Prefix$.
%because ${b(\Prefix', \x, \y) \ge b(\Prefix, \x, \y)}$. \\
%
For the objective of such a rule list, the current best objective
provides a lower bound, \ie
${\Obj(\RL', \x, \y) \ge b(\Prefix', \x, \y) \ge}$ ${b(\Prefix, \x, \y) \ge \CurrentObj}$,
and thus~$\RL'$ cannot be optimal.

\input{sections/bounds}

\input{sections/implementation-long}

\input{sections/experiments-long}

\input{sections/conclusion}

% Acknowledgements should go at the end, before appendices and references
\acks{E.A. conducted most of this work while supported by the Miller Institute for Basic Research
in Science, University of California, Berkeley, and hosted by Prof. M.I. Jordan at RISELab.
%
C.D.R. is supported in part by MIT-Lincoln Labs and the National Science Foundation under IIS-1053407.
%
E.A. would like to thank E.~Jonas, E.~Kohler, and S.~Tu for early implementation
guidance, A.~D'Amour for pointing out the work by~\citet{Goel16}, V.~Kanade, S.~McCurdy,
J.~Schleier-Smith and E.~Thewalt for helpful conversations, and members of RISELab,
SAIL, and the UC Berkeley Database Group for their support and feedback.
%
We thank H.~Yang and B.~Letham for sharing advice and code for processing data
and mining rules, B.~Coker for his critical advice on using the ProPublica COMPAS data set,
as well as V.~Kaxiras and A.~Saligrama for their recent contributions to our implementation
and for creating the CORELS website. We are very grateful to our editor and anonymous reviewers.
}

\vskip 0.2in

\renewcommand{\theHsection}{A\arabic{section}}
\appendix
%\renewcommand{\thesection}{\Alph{section}}
\input{sections/appendix-bounds}
\input{sections/appendix}

\bibliography{refs}

\end{document}
