\section{Learning optimal rule lists}

\subsection{Rule lists for binary classification}
\label{sec:setup}

We restrict our setting to binary classification,
where rule lists are Boolean functions;
this framework is straightforward to generalize to multi-class classification.
%
Let~${\{(x_n, y_n)\}_{n=1}^N}$ denote training data,
where ${x_n \in \{0, 1\}^J}$ are binary features and ${y_n \in \{0, 1\}}$ are labels.
%
Let~${\x = \{x_n\}_{n=1}^N}$ and~${\y = \{y_n\}_{n=1}^N}$,
and let~${x_{n,j}}$ denote the $j$-th feature of~$x_n$.

\begin{figure}[t!]
%\begin{subfigure}{0.18\textwidth}
%\begin{algorithmic}
%\normalsize
%\State \bif $p_1$ \bthen $q_1$
%\State \belif $p_2$ \bthen $q_2$
%\State \dots
%\State \belif $p_K$ \bthen $q_K$
%\State \belse $q_0$.
%\end{algorithmic}
%\end{subfigure}
%\begin{subfigure}{0.28\textwidth}
\begin{algorithmic}
\normalsize
\State \bif $(age=23-25) \wedge (priors=2-3)$ \bthen $yes$
\State \belif $(sex=male) \wedge (age=18-22)$ \bthen $yes$
\State \belif $(priors>3)$ \bthen $yes$
\State \belse $no$
\end{algorithmic}
%\end{subfigure}
%\caption{A $K$-rule list ${\RL = (r_1, r_2, \dots, r_K, r_0)}$, where
%each rule ${r_k = p_k \rightarrow q_k}$, for all ${k = 0, \dots K}$.
%We also equivalently write ${\RL = (\Prefix, \Labels, \Default, K)}$,
%where ${\Prefix = (p_1, \dots, p_K)}$
%and ${\Labels = (q_1, \dots, q_K)}$.}
\caption{An example 3-rule list ${\RL = (r_1, r_2, r_3, r_0)}$
that predicts two-year recidivism for the COMPAS dataset.
Each rule is of the form ${r_k = p_k \rightarrow q_k}$,
for all ${k = 0, \dots, 3}$.
We also equivalently write ${\RL = (\Prefix, \Labels, \Default, K)}$,
where ${\Prefix = (p_1, p_2, p_3)}$, ${\Labels = (1, 1, 1)}$,
${\Default = 0}$, and ${K=3}$.
}
\label{fig:rule-list}
\end{figure}

A rule list ${\RL = (r_1, r_2, \dots, r_K, r_0)}$ of length~${K \ge 0}$
is a ${(K+1)}$-tuple consisting of~$K$ distinct association rules,
${r_k = p_k \rightarrow q_k}$, for ${k = 1, \dots, K}$,
followed by a default rule~$r_0$.
%
Figure~\ref{fig:rule-list} illustrates~$\RL$,
which for clarity, we sometimes call a $K$-rule list.
%
An association rule~${r = p \rightarrow q}$ is an implication
corresponding to the conditional statement, ``if~$p$, then~$q$.''
%
In our setting, an antecedent~$p$ is a Boolean assertion that
evaluates to either true or false for each datum~$x_n$,
and a consequent~$q$ is a label prediction.
%
For example, ${(x_{n, 1} = 0) \wedge (x_{n, 3} = 1) \rightarrow (y_n = 1)}$
is an association rule.
%
%The number of conditions in an antecedent is its cardinality;
%the antecedent in the previous example has a cardinality of two.
%
The final default rule~$r_0$ in a rule list can be thought of
as a special association rule~${p_0 \rightarrow q_0}$
whose antecedent~$p_0$ simply asserts true.

Let ${\RL = (r_1, r_2, \dots, r_K, r_0)}$ be a $K$-rule list,
where ${r_k = p_k \rightarrow q_k}$ for each ${k = 0, \dots, K}$.
%
We introduce a useful alternate rule list representation:
${\RL = (\Prefix, \Labels, \Default, K)}$,
where we define ${\Prefix = (p_1, \dots, p_K)}$ to be $\RL$'s prefix,
${\Labels = (q_1, \dots, q_K) \in \{0, 1\}^K}$~gives
the label predictions associated with~$\Prefix$,
and we call ${\Default \in \{0, 1\}}$ the default label prediction.

Let ${\Prefix = (p_1, \dots, p_k, \dots, p_K)}$ be an antecedent list,
then for any ${k \le K}$, we define ${\Prefix^k = (p_1, \dots, p_k)}$
to be the $k$-prefix of~$\Prefix$.
%
For any such $k$-prefix~$\Prefix^k$,
we say that~$\Prefix$ starts with~$\Prefix^k$.
%
For any given space of rule lists,
we define~$\StartsWith(\Prefix)$ to be the set of
all rule lists whose prefixes start with~$\Prefix$:
\begin{align}
\StartsWith(\Prefix) =
\{(\Prefix', \Labels', \Default', K') : \Prefix' \textnormal{ starts with } \Prefix \}.
\label{eq:starts-with}
\end{align}
%We also say that an antecedent list~$\Prefix$ contains another
%antecedent list~$\Prefix'$ if the antecedents in~$\Prefix'$ correspond to
% a contiguous subsequence of antecedents anywhere in~$\Prefix$.
%
If ${\Prefix = (p_1, \dots, p_K)}$ and ${\Prefix' = (p_1, \dots, p_K, p_{K+1})}$
are two prefixes such that~$\Prefix'$ starts with~$\Prefix$ and extends it by
a single antecedent, we say that~$\Prefix$ is the parent of~$\Prefix'$
and that~$\Prefix'$ is a child of~$\Prefix$.

A rule list~$\RL$ classifies datum~$x_n$ by providing the label prediction~$q_k$
of the first rule~$r_k$ whose antecedent~$p_k$ is true for~$x_n$.
%
We say that an antecedent~$p_k$ of antecedent list~$\Prefix$ captures~$x_n$
in the context of~$\Prefix$ if~$p_k$ is the first antecedent in~$\Prefix$ that
evaluates to true for~$x_n$.
%
We also say that an antecedent list captures those data captured by its antecedents;
for a rule list~${\RL = (\Prefix, \Labels, \Default, K)}$,
data not captured by the prefix~$\Prefix$
are classified according to the default label prediction~$\Default$.

Let~$\beta$ be a set of antecedents.
%
We define~${\Cap(x_n, \beta) = 1}$ if an antecedent in~$\beta$
captures datum~$x_n$, and~0 otherwise.
%
For example, let~$\Prefix$ and~$\Prefix'$ be prefixes such that~$\Prefix'$ starts
with~$\Prefix$, then~$\Prefix'$ captures all the data that~$\Prefix$ captures:
\begin{align}
\{x_n: \Cap(x_n, \Prefix)\} \subseteq \{x_n: \Cap(x_n, \Prefix')\}.
\label{eq:cap-subset}
\end{align}
%We also define ${\Cap(\x, \beta) = \{\Cap(x_n, \beta)\}_{n=1}^N} \in \{0, 1\}^N$
%to be~$\beta$'s captures vector.
%
Now let~$\Prefix$ be an ordered list of antecedents,
and let~$\beta$ be a subset of antecedents in~$\Prefix$.
%
Let us define~${\Cap(x_n, \beta \given \Prefix) = 1}$ if~$\beta$
captures datum~$x_n$ in the context of~$\Prefix$,
\ie if the first antecedent in~$\Prefix$ that evaluates to true for~$x_n$
is an antecedent in~$\beta$, and~0 otherwise.
%
Note that ${\Cap(x_n, \beta \given \Prefix) = 1}$ only if ${\Cap(x_n, \beta) = 1}$;
${\Cap(x_n, \beta \given \Prefix) = 0}$ either if ${\Cap(x_n, \beta) = 0}$,
or if ${\Cap(x_n, \beta) = 1}$ but there is an antecedent~$\alpha$ in~$\Prefix$,
preceding all antecedents in~$\beta$, such that ${\Cap(x_n, \alpha) = 1}$.
%
For example, if ${\Prefix = (p_1, \dots, p_k, \dots, p_K)}$ is a prefix, then
\begin{align}
\Cap(x_n, p_k \given \Prefix) =
  \left(\bigwedge_{k'=1}^{k - 1} \neg\, \Cap(x_n, p_{k'}) \right)
  \wedge \Cap(x_n, p_k)
\end{align}
indicates whether antecedent~$p_k$ captures datum~$x_n$ in the context of~$\Prefix$.
%
Now, define~${\Supp(\beta, \x)}$ to be the normalized support of~$\beta$,
\begin{align}
\Supp(\beta, \x) = \frac{1}{N} \sum_{n=1}^N \Cap(x_n, \beta),
\label{eq:support}
\end{align}
and similarly define~${\Supp(\beta, \x \given \Prefix)}$
to be the normalized support of~$\beta$ in the context of~$\Prefix$,
\begin{align}
\Supp(\beta, \x \given \Prefix) = \frac{1}{N} \sum_{n=1}^N \Cap(x_n, \beta \given \Prefix),
\label{eq:support-context}
\end{align}

Finally, we address how empirical data constrains rule lists.
%
Given training data~${(\x, \y)}$,
an antecedent list ${\Prefix = (p_1, \dots, p_K)}$
implies a rule list ${\RL = (\Prefix, \Labels, \Default, K)}$
with prefix~$\Prefix$, where the label predictions
${\Labels = (q_1, \dots, q_K)}$ and~$\Default$ are empirically set
to minimize the number of misclassification errors made by
the rule list on the training data.
%
Thus for~${1 \le k \le K}$, label prediction~$q_k$ corresponds to the
majority label of data captured by antecedent~$p_k$ in the context of~$\Prefix$,
and the default~$\Default$ corresponds to the majority label of data
not captured by~$\Prefix$.
%
In the remainder of our presentation, whenever we refer to a rule list with a
particular prefix, we implicitly assume these empirically determined label predictions.

\subsection{Rule mining}
\label{sec:rule-mining}

Before proceeding, we describe our approach to rule mining,
which follows the methodology taken by~\citet{LethamRuMcMa15}
and~\citet{YangRuSe16} \dots

One of the results we prove later implies a constraint on the rules
we need to generate -- they must have at least some minimum support
given by the lower bound in Theorem~\ref{thm:min-capture}.

\begin{arxiv}
\subsection{Rule list representation and bit vector operations}
Something along these lines... look at~\citet{YangRuSe16}
\end{arxiv}

\subsection{Optimization framework}

\begin{arxiv}
We define
\end{arxiv}
\begin{kdd}
Define
\end{kdd}
a simple objective function for a rule list ${\RL = (\Prefix, \Labels, \Default, K)}$:
\begin{align}
\Obj(\RL, \x, \y) = \Loss(\RL, \x, \y) + \Reg K.
\label{eq:objective}
\end{align}
This objective function is a regularized empirical risk;
it consists of a loss~$\Loss(\RL, \x, \y)$, measuring misclassification error,
and a regularization term that penalizes longer rule lists.
%
$\Loss(\RL, \x, \y)$~is the fraction of training data whose labels are
incorrectly predicted by~$\RL$.
%
In our setting, the regularization parameter~${\Reg \ge 0}$ is a small constant;
\eg ${\Reg = 0.01}$ can be thought of as adding a penalty equivalent to misclassifying~$1\%$
of data when increasing a rule list's length by one association rule.
%
%As noted in~\S\ref{sec:setup}, a prefix~$\Prefix$ and training data together
%fully specify a rule list~${\RL = (\Prefix, \Labels, \Default, K)}$,
%thus let us define~${\Obj(\Prefix, \x, \y) \equiv \Obj(\RL, \x, \y)}$.

Our objective has structure amenable to global optimization via a branch-and-bound framework.
%
We can decompose the misclassification error into two contributions
corresponding to the prefix and default:
\begin{align}
\Loss(\RL, \x, \y) %= \Loss(\Prefix, r_q, \Default, \x, \y)
\equiv \Loss_p(\Prefix, \Labels, \x, \y) + \Loss_0(\Prefix, \Default, \x, \y),
\end{align}
where ${\Prefix = (p_1, \dots, p_K)}$ and ${\Labels = (q_1, \dots, q_K)}$;
\begin{align}
\Loss_p(\Prefix, \Labels, \x, \y) =
\frac{1}{N} \sum_{n=1}^N \sum_{k=1}^K \Cap(x_n, p_k \given \Prefix) \wedge \one [ q_k \neq y_n ]
\label{eq:loss}
\end{align}
is the fraction of data captured and misclassified by the prefix, and
\begin{align}
\Loss_0(\Prefix, \Default, \x, \y) =
\frac{1}{N} \sum_{n=1}^N \neg\, \Cap(x_n, \Prefix) \wedge \one [ \Default \neq y_n ]
\end{align}
is the fraction of data not captured by the prefix and misclassified by the default.
%
Eliminating the latter error term gives a lower bound~$b(\Prefix, \x, \y)$ on the objective,
\begin{align}
b(\Prefix, \x, \y) \equiv \Loss_p(\Prefix, \Labels, \x, \y) + \Reg K \le \Obj(\RL, \x, \y),
\label{eq:lower-bound}
\end{align}
where we have suppressed the lower bound's dependence on label predictions~$\Labels$
because they are fully determined, given~${(\Prefix, \x, \y)}$.
%
Furthermore, as we state next in Theorem~\ref{thm:bound},
$b(\Prefix, \x, \y)$ gives a lower bound on the objective of
\emph{any} rule list whose prefix starts with~$\Prefix$.

\begin{theorem}[Hierarchical objective lower bound]
Define~${b(\Prefix, \x, \y) = \Loss_p(\Prefix, \Labels, \x, \y) + \Reg K}$.
%
\begin{arxiv}
Also, define
${\StartsWith(\Prefix) = \{(\Prefix', \Labels', \Default', K') : \Prefix' \textnormal{ starts with } \Prefix \}}$
to be the set of all rule lists whose prefix starts with~$\Prefix$.
\end{arxiv}
\begin{kdd}
Also, define $\StartsWith(\Prefix)$
to be the set of all rule lists whose prefix starts with~$\Prefix$,
as in~\eqref{eq:starts-with}.
\end{kdd}
%
Let ${\RL = }$ ${(\Prefix, \Labels, \Default, K)}$ be a rule list
with prefix~$\Prefix$, and let
${\RL' = (\Prefix', \Labels', \Default', K')}$ $\in \StartsWith(\Prefix)$
be any rule list such that its prefix~$\Prefix'$ starts with~$\Prefix$
and ${K' \ge K}$, then ${b(\Prefix, \x, \y) \le \Obj(\RL', \x, \y)}$.
\label{thm:bound}
\end{theorem}

\begin{arxiv}
\begin{proof}
Let ${\Prefix = (p_1, \dots, p_K)}$ and ${\Labels = (q_1, \dots, q_K)}$;
let ${\Prefix' = (p_1, \dots, p_K, p_{K+1}, \dots, p_{K'})}$
and ${\Labels' = (q_1, \dots, q_K, q_{K+1}, \dots, q_{K'})}$.
%
Notice that~$\Prefix'$ yields the same mistakes as~$\Prefix$,
and possibly additional mistakes:
\begin{align}
\Loss_p(\Prefix', \Labels', \x, \y)
&= \frac{1}{N} \sum_{n=1}^N \left( \sum_{k=1}^K \Cap(x_n, p_k \given \Prefix) \wedge \one [ q_k \neq y_n ]
+ \sum_{k=K+1}^{K'} \Cap(x_n, p_k \given \Prefix') \wedge \one [ q_k \neq y_n ] \right) \nn \\
&\ge \Loss_p(\Prefix, \Labels, \x, \y),
\label{eq:prefix-loss}
\end{align}
where we have used the fact that
${\Cap(x_n, p_k \given \Prefix') = \Cap(x_n, p_k \given \Prefix)}$
for~${1 \le k \le K}$.
%
It follows that
\begin{align}
b(\Prefix, \x, \y) &= \Loss_p(\Prefix, \Labels, \x, \y) + \Reg K \nn \\
&\le  \Loss_p(\Prefix', \Labels', \x, \y) + \Reg K' = b(\Prefix', \x, \y)
\le \Obj(\RL', \x, \y).
\label{eq:prefix-lb}
\end{align}
\end{proof}
\end{arxiv}

To generalize, consider a sequence of prefixes such that each prefix
starts with all previous prefixes in the sequence.
%
It follows that the corresponding sequence of objective lower bounds
increases monotonically.
%
This is precisely the structure required and exploited by branch-and-bound,
illustrated in Algorithm~\ref{alg:branch-and-bound}.

\begin{algorithm}[t!]
\caption{Branch-and-bound for learning rule lists.}
\label{alg:branch-and-bound}
\begin{algorithmic}
\normalsize
\State \textbf{Input:} Objective function $\Obj(\RL, \x, \y)$,
objective lower bound ${b(\Prefix, \x, \y)}$,
set of antecedents ${\RuleSet = \{s_m\}_{m=1}^M}$,
training data $(\x, \y) = {\{(x_n, y_n)\}_{n=1}^N}$,
initial best known rule list~$\InitialRL$ with objective
${\InitialObj = \Obj(\InitialRL, \x, \y)}$
\State \textbf{Output:} Provably optimal rule list~$\OptimalRL$ with minimum objective~$\OptimalObj$ \\

\State $(\CurrentRL, \CurrentObj) \gets (\InitialRL, \InitialObj)$ \Comment{Initialize best rule list and objective}
\State $Q \gets $ queue$(\,[\,(\,)\,]\,)$ \Comment{Initialize queue with empty prefix}
\While {$Q$ not empty} \Comment{Stop when queue is empty}
	\State $\Prefix \gets Q$.pop(\,) \Comment{Remove prefix~$\Prefix$ from the queue}
	\If {$b(\Prefix, \x, \y) < \CurrentObj$} \Comment{\textbf{Bound}: Apply Theorem~\ref{thm:bound}}
        \State $\Obj \gets \Obj(\RL, \x, \y)$ \Comment{Compute objective of~$\Prefix$'s rule list~$\RL$}
        \If {$\Obj < \CurrentObj$} \Comment{Update best rule list and objective}
            \State $(\CurrentRL, \CurrentObj) \gets (\RL, \Obj)$
        \EndIf
        \For {$s$ in $\RuleSet$} \Comment{\textbf{Branch}: Enqueue~$\Prefix$'s children}
            \If {$s$ not in $\Prefix$}
                \State $Q$.push$(\,(\Prefix, s)\,)$
            \EndIf
        \EndFor
    \EndIf
\EndWhile
\State $(\OptimalRL, \OptimalObj) \gets (\CurrentRL, \CurrentObj)$ \Comment{Identify provably optimal solution}
\end{algorithmic}
\end{algorithm}

Specifically, the objective lower bound in Theorem~\ref{thm:bound}
enables us to prune the state space hierarchically.
%
While executing branch-and-bound, we keep track of the current best (smallest)
objective~$\CurrentObj$, thus it is a dynamic, monotonically decreasing quantity.
%
If we encounter a prefix~$\Prefix$ with lower bound
${b(\Prefix, \x, \y) \ge \CurrentObj}$,
then by Theorem~\ref{thm:bound}, we needn't consider \emph{any}
rule list~${\RL' \in \StartsWith(\Prefix)}$ whose prefix~$\Prefix'$ starts with~$\Prefix$.
%because ${b(\Prefix', \x, \y) \ge b(\Prefix, \x, \y)}$. \\
%
For the objective of such a rule list, the current best objective
provides a lower bound, \ie
${\Obj(\RL', \x, \y) \ge b(\Prefix', \x, \y) \ge}$ ${b(\Prefix, \x, \y) \ge \CurrentObj}$,
and thus~$\RL'$ cannot be optimal. \\

\subsection{Incremental computation}
\label{sec:incremental}

For every prefix~$\Prefix$ evaluated during
Algorithm~\ref{alg:branch-and-bound}'s execution, we compute
the objective lower bound~${b(\Prefix, \x, \y)}$ and, sometimes,
the objective~${\Obj(\RL, \x, \y)}$ of the corresponding rule list~$\RL$.
%
These calculations are the dominant computations with respect to execution time.
%
This motivates our use of a highly optimized library,
designed by~\citet{YangRuSe16} for representing rule lists and
performing operations encountered in evaluating functions of rule lists.
%
Furthermore, we exploit the hierarchical nature of the objective
function and its lower bound to compute these quantities
incrementally throughout branch-and-bound execution.
%
\begin{arxiv}
In this section, we provide explicit expressions for
the incremental computations that are central to our approach.
\end{arxiv}
%
Later, in~\S\ref{sec:implementation}, we describe a cache data structure
for supporting our incremental framework in practice.

\begin{arxiv}
For completeness, before presenting our incremental expressions,
let us begin by writing down the objective lower bound and objective
of the empty rule list, ${\RL = ((), (), \Default, 0)}$,
the first rule list evaluated in Algorithm~\ref{alg:branch-and-bound}.
%
Since its prefix contains zero rules, it has zero prefix
misclassification error and also has length zero.
%
Thus, the empty rule list's objective lower bound is zero:
\begin{align}
  b((), \x, \y) = \Loss_p((), (), \x, \y) + \Reg \cdot 0 = 0.
\end{align}
%
Since none of the data are captured by the empty prefix, the default rule
corresponds to the majority class, and the objective corresponds to the
default rule misclassification error, \ie
\begin{align}
  \Obj(\RL, \x, \y) = \Loss(\RL, \x, \y) + \Reg \cdot 0
  &= \Loss_p((), (), \x, \y) + \Loss_0((), \Default, \x, \y) \nn \\
  &= b((), \x, \y) + \Loss_0((), \Default, \x, \y) = \Loss_0((), \Default, \x, \y).
\end{align}

Now, we derive our incremental expressions for the objective function and its lower bound.
%
Let ${\RL = (\Prefix, \Labels, \Default, K)}$ and
${\RL' = (\Prefix', \Labels', \Default', K + 1)}$
be rule lists such that prefix ${\Prefix = (p_1, \dots, p_K)}$
is the parent of ${\Prefix' = (p_1, \dots, p_K, p_{K+1})}$.
%
Let ${\Labels = (q_1, \dots, q_K)}$ and
${\Labels' = (q_1, \dots, q_K, q_{K+1})}$ be the corresponding labels.
%
The hierarchical structure of Algorithm~\ref{alg:branch-and-bound}
enforces that if we ever evaluate~$\RL'$, then we will have already
evaluated both the objective and objective lower bound of its parent,~$\RL$.
%
We would like to reuse as much of these computations as possible
in our evaluation of~$\RL'$.
%
We can write the objective lower bound of~$\RL'$ incrementally,
with respect to the objective lower bound of~$\RL$:
\begin{align}
b(\Prefix', \Labels', \x, \y)
  &= \Loss_p(\Prefix', \Labels', \x, \y) + \Reg (K + 1) \nn \\
&= \frac{1}{N} \sum_{n=1}^N \sum_{k=1}^{K+1} \Cap(x_n, p_k \given \Prefix')
  \wedge \one [ q_k \neq y_n ] + \Reg (K+1) \label{eq:non-inc-lb} \\
&= \Loss_p(\Prefix, \Labels, \x, \y) + \Reg K + \Reg
  + \frac{1}{N} \sum_{n=1}^N \Cap(x_n, p_{K+1} \given \Prefix') \wedge \one [q_{K+1} \neq y_n ] \nn \\
&= b(\Prefix, \Labels, \x, \y) + \Reg
  + \frac{1}{N} \sum_{n=1}^N \Cap(x_n, p_{K+1} \given \Prefix') \wedge \one [q_{K+1} \neq y_n ] \nn \\
&= b(\Prefix, \Labels, \x, \y) + \Reg  + \frac{1}{N} \sum_{n=1}^N \neg\, \Cap(x_n, \Prefix) \wedge
  \Cap(x_n, p_{K+1}) \wedge \one [q_{K+1} \neq y_n].
\label{eq:inc-lb}
\end{align}
%Notice that the term~${\neg\, \Cap(x_n, \Prefix)}$ in~\eqref{eq:inc-lb}
%depends only on~$\Prefix$, \ie it does not depend on~$\Prefix'$; furthermore,
%it is computed in the evaluation of~$\RL$'s default rule misclassification error,
%\begin{align}
%\Loss_0(\Prefix, \Default, \x, \y) = \frac{1}{N}\sum_{n=1}^N \neg\, \Cap(x_n, \Prefix) \wedge \one [q_0 \neq y_n].
%\end{align}
Thus, if we store $b(\Prefix, \Labels, \x, \y)$, % and ${\neg\, \Cap(\x, \Prefix)}$,
then we can reuse this quantity when computing $b(\Prefix', \Labels', \x, \y)$.
%
Transforming~\eqref{eq:non-inc-lb} into~\eqref{eq:inc-lb} yields a
significantly simpler expression that is a function of the stored
quantity~$b(\Prefix, \Labels, \x, \y)$. %, as well as ${\neg\, \Cap(\x, \Prefix)}$
%and the last rule of~$\RL'$, ${p_{K+1} \rightarrow q_{K+1}}$.
%
For the objective of~$\RL'$, first let us write a na\"ive expression:
\begin{align}
\Obj(\RL', \x, \y) &= \Loss(\RL', \x, \y) + \Reg (K + 1)
= \Loss_p(\Prefix', \Labels', \x, \y) + \Loss_0(\Prefix', \Default', \x, \y) + \Reg(K + 1) \nn \\
&= \frac{1}{N} \sum_{n=1}^N \sum_{k=1}^{K+1} \Cap(x_n, p_k \given \Prefix')
  \wedge \one [ q_k \neq y_n ] + \frac{1}{N}\sum_{n=1}^N \neg\, \Cap(x_n, \Prefix') \wedge
  \one [q'_0 \neq y_n] + \Reg (K+1). \label{eq:non-inc-obj}
\end{align}
Instead, we can compute the objective of~$\RL'$ incrementally
with respect to its objective lower bound:
\begin{align}
\Obj(\RL', \x, \y) &=  \Loss_p(\Prefix', \Labels', \x, \y) +
  \Loss_0(\Prefix', \Default', \x, \y) + \Reg (K + 1) \nn \\
&= b(\Prefix', \Labels', \x, \y) + \Loss_0(\Prefix', \Default', \x, y) \nn \\
&= b(\Prefix', \Labels', \x, \y) + \frac{1}{N}\sum_{n=1}^N \neg\, \Cap(x_n, \Prefix') \wedge
  \one [q'_0 \neq y_n] \nn \\
&= b(\Prefix', \Labels', \x, \y) + \frac{1}{N}\sum_{n=1}^N \neg\, \Cap(x_n, \Prefix) \wedge
  (\neg\, \Cap(x_n, p_{K+1})) \wedge \one [q'_0 \neq y_n].
\label{eq:inc-obj}
\end{align}
The expression in~\eqref{eq:inc-obj} is much simpler than the na\"ive
one in~\eqref{eq:non-inc-obj}, and is a function of
$b(\Prefix', \Labels', \x, \y)$, which we computed in~\eqref{eq:inc-lb}.
%as well as ${\neg\, \Cap(\x, \Prefix)}$,
%and the last antecedent~$p_{K+1}$ and default rule~$\Default'$ of~$\RL'$.
Though we could compute the objective of~$\RL'$ incrementally
with respect to that of~$\RL$, doing so would in practice require
that we also store~$\Obj(\RL, \x, \y)$; we prefer the approach suggested
by~\eqref{eq:inc-obj} since it avoids this additional storage overhead.

\begin{algorithm}[t!]
  \caption{Incremental branch-and-bound for learning rule lists, for simplicity, from a cold start.
  We explicitly show the incremental objective lower bound and objective functions in Algorithm~\ref{alg:incremental-functions}.}
\label{alg:incremental}
\begin{algorithmic}
\normalsize
\State \textbf{Input:} Objective function~$\Obj(\RL, \x, \y)$,
objective lower bound~${b(\Prefix, \x, \y)}$,
set of antecedents ${\RuleSet = \{s_m\}_{m=1}^M}$,
training data~$(\x, \y) = {\{(x_n, y_n)\}_{n=1}^N}$,
regularization parameter~$\Reg$
\State \textbf{Output:} Provably optimal rule list~$\OptimalRL$ with minimum objective~$\OptimalObj$ \\

\State $\CurrentRL \gets ((), (), \Default, 0)$ \Comment{Initialize current best rule list with empty rule list}
\State $\CurrentObj \gets \Obj(\CurrentRL, \x, \y)$ \Comment{Initialize current best objective}
\State $Q \gets $ queue$(\,[\,(\,)\,]\,)$ \Comment{Initialize queue with empty prefix}
\State $C \gets $ cache$(\,[\,(\,(\,)\,, 0\,)\,]\,)$ \Comment{Initialize cache with empty prefix and its objective lower bound}
\While {$Q$ not empty} \Comment{Optimization complete when the queue is empty}
	\State $\Prefix \gets Q$.pop(\,) \Comment{Remove a prefix~$\Prefix$ from the queue}
        \State $b(\Prefix, \x, \y) \gets C$.find$(\Prefix)$ \Comment{Look up $\Prefix$'s lower bound in the cache}
        \State $\mathbf{u} \gets \neg\,\Cap(\x, \Prefix)$ \Comment{Bit vector indicating data not captured by $\Prefix$}
        \For {$s$ in $\RuleSet$} \Comment{Evaluate all of $\Prefix$'s children}
            \If {$s$ not in $\Prefix$}
                \State $\PrefixB \gets (\Prefix, s)$ \Comment{\textbf{Branch}: Generate child $\PrefixB$}
                \State $\mathbf{v} \gets \mathbf{u} \wedge \Cap(\x, s)$ \Comment{Bit vector indicating data captured by $s$ in $\PrefixB$}
                \State $b(\PrefixB, \x, \y) \gets b(\Prefix, \x, \y) + \Reg~ + $ \Call{IncrementalLowerBound}{$\mathbf{v}, \y, N$} \Comment{Eq.~\eqref{eq:inc-lb}}
                \If {$b(\PrefixB, \x, \y) < \CurrentObj$} \Comment{\textbf{Bound}: Apply bound from Theorem~\ref{thm:bound}}
                    \State $\Obj(\RLB, \x, \y) \gets b(\PrefixB, \x, \y)~ + $ \Call{IncrementalObjective}{$\mathbf{u}, \mathbf{v}, \y, N$} \Comment{Eq.~\eqref{eq:inc-obj}}
                    \If {$\Obj(\RLB, \x, \y) < \CurrentObj$}
                        \State $(\CurrentRL, \CurrentObj) \gets (\RLB, \Obj(\RLB, \x, \y))$ \Comment{Update current best rule list and objective}
                    \EndIf
                    \State $Q$.push$(\PrefixB)$ \Comment{Add $\PrefixB$ to the queue}
                    \State $C$.insert$(\PrefixB, b(\PrefixB, \x, \y))$ \Comment{Add $\PrefixB$ and its lower bound to the cache}
                \EndIf
            \EndIf
        \EndFor
\EndWhile
\State $(\OptimalRL, \OptimalObj) \gets (\CurrentRL, \CurrentObj)$ \Comment{Identify provably optimal rule list and objective}
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[t!]
  \caption{Incremental objective lower bound~\eqref{eq:inc-lb} used in Algorithm~\ref{alg:incremental}.}
\label{alg:incremental-lb}
\begin{algorithmic}
\normalsize
\State \textbf{Input:}
Bit vector~${\mathbf{v} \in \{0, 1\}^N}$ indicating data captured by $s$, the last antecedent in~$\PrefixB$,
bit vector of class labels~${\y \in \{0, 1\}^N}$,
number of observations~$N$
\State \textbf{Output:} Component of~$\RLB$'s misclassification error due to data captured by~$s$ \\

\Function{IncrementalLowerBound}{$\mathbf{v}, \y, N$}
    \State $n_v = \Count(\mathbf{v})$ \Comment{Number of data captured by $s$, the last antecedent in $\PrefixB$}
    \State $\mathbf{w} \gets \mathbf{v} \wedge \y$ \Comment{Bit vector indicating data captured by $s$ with label $1$}
    \State $n_w = \Count(\mathbf{w})$ \Comment{Number of data captured by $s$ with label $1$}
    \If {$n_w / n_v > 0.5$}
        \State \Return $(n_v - n_w) / N$ \Comment{Misclassification error of the rule $s \rightarrow 1$}
    \Else
        \State \Return $n_w / N$ \Comment{Misclassification error of the rule $s \rightarrow 0$}
    \EndIf
    \EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[t!]
  \caption{Incremental objective function~\eqref{eq:inc-obj} used in Algorithm~\ref{alg:incremental}.}
\label{alg:incremental-obj}
\begin{algorithmic}
\normalsize
\State \textbf{Input:}
Bit vector~${\mathbf{u} \in \{0, 1\}^N}$ indicating data not captured by~$\PrefixB$'s parent prefix,
bit vector~${\mathbf{v} \in \{0, 1\}^N}$ indicating data not captured by $s$, the last antecedent in~$\PrefixB$,
bit vector of class labels~${\y \in \{0, 1\}^N}$,
number of observations~$N$
\State \textbf{Output:} Component of~$\RLB$'s misclassification error due to its default rule \\

 \Function{IncrementalObjective}{$\mathbf{u}, \mathbf{v}, \y, N$}
    \State $\mathbf{f} \gets \mathbf{u} \wedge \neg\,\mathbf{v} $ \Comment{Bit vector indicating data not captured by $\PrefixB$}
    \State $n_f = \Count(\mathbf{f})$ \Comment{Number of data not captured by $\PrefixB$}
    \State $\mathbf{g} \gets \mathbf{f} \wedge \y$ \Comment{Bit vector indicating data not captured by $\PrefixB$ with label $1$}
    \State $n_g = \Count(\mathbf{w})$ \Comment{Number of data not captued by $\PrefixB$ with label $1$}
    \If {$n_f / n_g > 0.5$}
        \State \Return $(n_f - n_g) / N$ \Comment{Default rule misclassification error with label $1$}
    \Else
        \State \Return $n_g / N$ \Comment{Default rule misclassification error with label $0$}
    \EndIf
\EndFunction
\end{algorithmic}
\end{algorithm}

We present an incremental branch-and-bound procedure in
Algorithm~\ref{alg:incremental}, and show the incremental computations
of the objective lower bound~\eqref{eq:inc-lb} and objective~\eqref{eq:inc-obj}
as two separate functions in Algorithms~\ref{alg:incremental-lb}
and~\ref{alg:incremental-obj}, respectively.
%
In Algorithm~\ref{alg:incremental}, we use a cache to store
prefixes and their objective lower bounds.
%
Algorithm~\ref{alg:incremental} additionally reorganizes the structure
of Algorithm~\ref{alg:branch-and-bound} to group together the computations
associated with all children of a particular prefix.
%
This has two advantages.
%
The first is to consolidate cache queries: all children of the same
parent prefix compute their objective lower bounds with respect to
the parent's stored value, and we only require one cache `find' operation
for the entire group of children, instead of a separate query for each child.
%
The second is to shrink the queue's size:
instead of adding all of a prefix's children as separate queue elements,
we represent the entire group of children in the queue by a single element.
%
Since the number of children associated with each prefix
is close to the total number of possible antecedents,
both of these effects can yield significant savings.
%
For example, if we are trying to optimize over rule lists formed
from a set of 1000 antecedents, then the maximum queue size in
Algorithm~\ref{alg:incremental} will be smaller than that in
Algorithm~\ref{alg:branch-and-bound} by a factor of nearly 1000.

\end{arxiv}
