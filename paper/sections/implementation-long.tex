\input{sections/incremental}

\section{Implementation}
\label{sec:implementation}

We implement our algorithm using a collection of optimized data structures
that we describe in this section.
%
First, we explain how we use a prefix tree~(\S\ref{sec:trie})
to support the incremental computations that we motivated in~\S\ref{sec:incremental}.
%
Second, we describe several queue designs
that implement different search policies~(\S\ref{sec:queue}).
%
Third, we introduce a symmetry-aware map~(\S\ref{sec:pmap}) to support
symmetry-aware pruning~(Corollary~\ref{thm:permutation},~\S\ref{sec:permutation}).
%
Next, we summarize how these data structures interact throughout
our model of incremental execution~(\S\ref{sec:execution}).
%
In particular, Algorithms~\ref{alg:bounds} and~\ref{alg:pmap} illustrate many
of the computational details from CORELS's inner loop, and highlight each of
the bounds from~\S\ref{sec:framework} that we use to prune the search space.
%
We additionally describe how we garbage collect our data structures~(\S\ref{sec:gc}).
%
Finally, we explore how our queue can be used to support
custom scheduling policies designed to improve performance~(\S\ref{sec:scheduling}).
%
Our implementation of CORELS can be found~at: \\

\centerline{\url{https://github.com/nlarusstone/corels}.}

\subsection{Prefix tree}
\label{sec:trie}

Our incremental computations (\S\ref{sec:incremental}) require a
cache to keep track of prefixes that we have already evaluated
and are still of interest.
%
We implement this cache as a prefix tree, a data structure also known as a trie,
which allows us to efficiently represent structure shared between related prefixes.
%
Each node in the prefix tree encodes an individual rule ${r_k = p_k \rightarrow q_k}$.
%
Each path starting from the root represents a prefix, such that the final node
in the path also contains metadata associated with that prefix.
%
For a %rule list ${\RL = (\Prefix, \Labels, \Default, K)}$, with
prefix ${\Prefix = (p_1, \dots, p_K)}$,
let~$\varphi(\Prefix)$ denote the corresponding node in the trie.
%
The metadata at node~$\varphi(\Prefix)$ supports the incremental computation
and includes:
\begin{itemize}
\item An index encoding~$p_K$, the last antecedent.
\item The objective lower bound $b(\Prefix, \x, \y)$, defined in~\eqref{eq:lower-bound},
  the central bound in our framework (Theorem~\ref{thm:bound}).
\item The lower bound on the default rule misclassification error
  $b_0(\Prefix, \x, \y)$, defined in~\eqref{eq:lb-b0},
  to support our equivalent points bound (Theorem~\ref{thm:identical}).
\item An indicator denoting whether this node should be deleted (see~\S\ref{sec:gc}).
\item A representation of viable extensions of~$\Prefix$,
  \ie length ${K+1}$ prefix that start with~$\Prefix$ and have not been pruned.
\end{itemize}
For evaluation purposes and convenience, we store additional information in
the prefix tree; for a prefix~$\Prefix$ with corresponding rule list
${\RL = (\Prefix, \Labels, \Default, K)}$, the node~$\varphi(\Prefix)$ also stores:
\begin{itemize}
\item The length~$K$; equivalently, node~$\varphi(\Prefix)$'s depth in the trie. 
\item The label prediction~$q_K$ corresponding to antecedent~$p_K$.
\item The default rule label prediction~$\Default$.
\item $\NCap$, the number of samples captured by prefix $\Prefix$, as in~\eqref{eq:num-cap}.
\item The objective value $\Obj(\RL, \x, \y)$, defined in~\eqref{eq:objective}.
\end{itemize}
%
Finally, we note that we implement the prefix tree as a custom C++ class. % decouple artifact from design
%
% This might be a bit much detail for here
%In addition to our base trie class, we also implemented a different node type that we use in our algorithm.
%This sub-class has an additional field that can hold custom metrics that we use to order the search space.
%Since this additional field is just a double, the memory overhead is minimal.
%
% Interesting trie-related subroutines besides garbage collection?

\subsection{Queue}
\label{sec:queue}

The queue is a worklist that orders exploration over the search space of possible
rule lists; every queue element corresponds to leaf in the prefix tree, and vice versa.
%
In our implementation, each queue element points to a leaf;
when we pop an element off the queue, we use the leaf's metadata to
incrementally evaluate the corresponding prefix's children.

We order entries in the queue to implement several different search policies.
%
For example, a first-in-first-out~(FIFO) queue implements breadth-first search~(BFS),
and a priority queue implements best-first search.
%
In our experiments~(\S\ref{sec:experiments}), we use the C++ Standard Template Library~(STL)
queue and priority queue to implement BFS and best-first search, respectively.
%
For CORELS, priority queue policies of interest include ordering by the lower bound,
the objective, or more generally, any function that maps prefixes to real values;
ordering by prefix length and inverse prefix length implement
BFS and depth-first search (DFS), respectively.
%
In our released code, we present a unified implementation,
where we use the STL priority queue to support BFS, DFS,
and several best-first search policies.
%
As we demonstrate in our experiments~(\S\ref{sec:ablation}),
we find that using a custom search strategy,
such as ordering by the lower bound, usually leads to a faster runtime than BFS.

We motivate the design of additional custom search strategies in~\S\ref{sec:curiosity}.
%
In preliminary work (not shown), we also experimented with
stochastic exploration processes that bypass the need for a queue
by instead following random paths from the root to leaves;
developing such methods could be an interesting direction for future work.

\subsection{Symmetry-aware map}
\label{sec:pmap}

The symmetry-aware map supports the symmetry-aware pruning justified in~\S\ref{sec:equivalent}.
%
In our implementation, we specifically leverage our permutation bound
(Corollary~\ref{thm:permutation}), though it is also possible to directly
exploit the more general equivalent support bound (Theorem~\ref{thm:equivalent}).
%
We use the C++ STL unordered map to keep track of the best known ordering
of each evaluated set of antecedents.
%
The keys of our symmetry-aware map encode antecedents in canonical order,
\ie antecedent indices in numerically sorted order,
and we associate all permutations of a set of antecedents with a single key.
%
Each key maps to a value that encodes the best known prefix in the permutation
group of the key's antecedents, as well as the objective lower bound of that prefix.

Before we consider adding a prefix~$\Prefix$ to the trie and queue, we check
whether the map already contains a permutation~$\pi(\Prefix)$ of that prefix.
%
If no such permutation exists, then we insert~$\Prefix$ into the map, trie, and queue.
%
Otherwise, if a permutation~$\pi(\Prefix)$ exists and the lower bound of~$\Prefix$ is better
than that of~$\pi(\Prefix)$, \ie ${b(\Prefix, \x, \y) <}$ ${b(\pi(\Prefix), \x, \y)}$,
then we update the map and remove~$\pi(\Prefix)$ and its entire subtree from the trie;
we also insert~$\Prefix$ into the trie and queue.
%
Otherwise, if there exists a permutation~$\pi(\Prefix)$ such that
${b(\pi(\Prefix), \x, \y) \le}$ ${b(\Prefix, \x, \y)}$,
then we do nothing, \ie we do not insert~$\Prefix$ into any data structures.

\subsection{Incremental execution}
\label{sec:execution}

\begin{algorithm}[t!]
  \caption{The inner loop of CORELS, which evaluates all children of a prefix~$\Prefix$.}
%  For details about symmetry-aware map queries, see Algorithm~\ref{alg:pmap}.}
\label{alg:bounds}
\begin{algorithmic}
\small
\State Define $\mathbf{z} \in \{0, 1\}^N$, s.t. ${z_n = \sum_{u=1}^U \one [x_n \in e_u] [y_n = q_u]}$ \Comment{$e_u$ and~$q_u$ are defined as in~\S\ref{sec:identical}}
\State Define $b(\Prefix, \x, \y)$ and $\mathbf{u} = \neg\,\Cap(\x, \Prefix)$ \Comment{$\mathbf{u}$ is a bit vector indicating data not captured by $\Prefix$} \\

\For {$s$ in $\RuleSet$ \textbf{if} $s$ not in $\Prefix$ \textbf{then}} \Comment{Evaluate all of $\Prefix$'s children}
%    \If {$s$ not in $\Prefix$}
        \State $\PrefixB \gets (\Prefix, s)$ \Comment{\textbf{Branch}: Generate child $\PrefixB$}
        \State $\mathbf{v} \gets \mathbf{u} \wedge \Cap(\x, s)$ \Comment{Bit vector indicating data captured by $s$ in $\PrefixB$}
        \State $n_v = \Count(\mathbf{v})$ \Comment{Number of data captured by $s$, the last antecedent in $\PrefixB$}
        \If {$n_v < \Reg$}
            \State \Continue \Comment{\textbf{Lower bound on antecedent support (Theorem\ref{thm:min-capture})}}
        \EndIf
        \State $\mathbf{w} \gets \mathbf{v} \wedge \y$ \Comment{Bit vector indicating data captured by $s$ with label $1$}
        \State $n_w = \Count(\mathbf{w})$ \Comment{Number of data captured by $s$ with label $1$}
       \If {$n_w < \Reg$}
           \State \Continue \Comment{\textbf{Lower bound on accurate antecedent support (Theorem~\ref{thm:min-capture-correct})}}
       \EndIf
       \If {$n_w / n_v > 0.5$}
           \State $\delta b \gets (n_v - n_w) / N$ \Comment{Misclassification error of the rule $s \rightarrow 1$}
       \Else
           \State $\delta b \gets n_w / N$ \Comment{Misclassification error of the rule $s \rightarrow 0$}
       \EndIf
       \State $b(\PrefixB, \x, \y) \gets b(\Prefix, \x, \y) + \Reg + \delta b$ \Comment{Incremental lower bound~\eqref{eq:inc-lb}}
       \If {$b(\PrefixB, \x, \y) + \Reg \ge \CurrentObj$} \Comment{\textbf{Hierarchical objective lower bound (Theorem~\ref{thm:bound})}}
           \State \Continue \hfill {combined with the \textbf{Lookahead bound (Lemma~\ref{lemma:lookahead})}}
       \EndIf
       \State $\mathbf{f} \gets \mathbf{u} \wedge \neg\,\mathbf{v} $ \Comment{Bit vector indicating data not captured by $\PrefixB$}
       \State $n_f = \Count(\mathbf{f})$ \Comment{Number of data not captured by $\PrefixB$}
       \State $\mathbf{g} \gets \mathbf{f} \wedge \y$ \Comment{Bit vector indicating data not captured by $\PrefixB$ with label $1$}
       \State $n_g = \Count(\mathbf{g})$ \Comment{Number of data not captued by $\PrefixB$ with label $1$}
       \If {$n_g / n_f > 0.5$}
           \State $\delta\Obj \gets (n_f - n_g) / N$ \Comment{Misclassification error of the default label prediction $1$}
       \Else
           \State $\delta\Obj \gets n_g / N$ \Comment{Misclassification error of the default label prediction $0$}
       \EndIf
       \State $\Obj(\RLB, \x, \y) \gets b(\PrefixB, \x, \y) + \delta\Obj$ \Comment{Incremental objective~\eqref{eq:inc-obj}}
       %\State $\Obj(\RLB, \x, \y) \gets b(\PrefixB, \x, \y)~ + $ \Call{IncrementalObjective}{$\mathbf{u}, \mathbf{v}, \y, N$}  \Comment{Inc. objective~\eqref{eq:inc-lb}}
       \State $\RLB \gets (\PrefixB, \LabelsB, \DefaultB, K+1)$ \Comment{$\LabelsB, \DefaultB$ are set in the incremental functions}
       \If {$\Obj(\RLB, \x, \y) < \CurrentObj$}
            \State $(\CurrentRL, \CurrentObj) \gets (\RLB, \Obj(\RLB, \x, \y))$ \Comment{Update current best rule list and objective}
            \State \Call{GarbageCollectPrefixTree}{$\CurrentObj$} \Comment{Delete nodes with lower bound $< \CurrentObj$ (\S\ref{sec:gc})}
        \EndIf
        \State $b_0(\PrefixB, \x, \y) \gets \Count(\mathbf{f} \wedge \mathbf{z}) / N$ \Comment{Lower bound on the default rule misclassification}
        \State $b \gets b(\PrefixB, \x, \y) + b_0(\PrefixB, \x, \y)$ \hfill error defined in~\eqref{eq:lb-b0}
        \If {$b \ge \CurrentObj$}
            \State \Continue \Comment{\textbf{Equivalent points bound (Theorem~\ref{thm:identical})}}
        \EndIf
        \State \Call{CheckMapAndInsert}{$\PrefixB, b$} \Comment{Check the \textbf{Permutation bound (Corollary~\ref{thm:permutation})} and}
        %\If {\Call{CheckSymmetryAwareMap}{$\PrefixB, b$}} \Comment{\textbf{Permutation bound (Corollary~\ref{thm:permutation})}}
        %    \State $Q$.push$(\PrefixB)$ \Comment{Add $\PrefixB$ to the queue}
        %    \State $C$.insert$(\PrefixB, b(\PrefixB, \x, \y))$ \Comment{Add $\PrefixB$ and its lower bound to the cache}
        %\EndIf
%    \EndIf
\EndFor \hfill {possibly insert $\PrefixB$ into data structures (Algorithm~\ref{alg:pmap})}
\end{algorithmic}
\end{algorithm}


\begin{algorithm}[t!]
  \caption{Possibly insert a prefix into CORELS's data structures, after first
  checking the symmetry-aware map, which supports search space pruning
  triggered by the permutation bound (Corollary~\ref{thm:permutation}).
  For further context, see Algorithm~\ref{alg:bounds}.}
\label{alg:pmap}
\begin{algorithmic}
\State $T$ is the prefix tree (\S\ref{sec:trie})
\State $Q$ is the queue, for concreteness, a priority queue ordered by the lower bound (\S\ref{sec:queue})
\State $\PMap$ is the symmetry-aware map (\S\ref{sec:pmap}) \\

\Function{CheckMapAndInsert}{$\PrefixB, b$}
    \State $\pi_0 \gets$ sort($\PrefixB$) \Comment{$\PrefixB$'s antecedents in canonical order}
    \State $(D_\pi, b_\pi) \gets \PMap$.find($\pi_0$) \Comment{Look for a permutation of $\PrefixB$}
    \If {$D_\pi$ exists}
        \If {$b < b_\pi$} \Comment{$\PrefixB$ is better than $D_\pi$}
            \State $\PMap$.update($\pi_0, (\PrefixB, b)$) \Comment{Replace $D_\pi$ with $\PrefixB$ in the map}
            \State $T$.delete\_subtree($D_\pi$) \Comment{Delete $D_\pi$ and its subtree from the prefix tree}
            \State $T$.insert$(\varphi(\PrefixB))$ \Comment{Add node for $\PrefixB$ to the prefix tree}
            \State $Q$.push$(\PrefixB, b)$ \Comment{Add $\PrefixB$ to the queue}
        \Else
            \State \textbf{pass} \Comment{$\PrefixB$ is inferior to $D_\pi$, thus do not insert it into any data structures}
        \EndIf
    \Else
        \State $\PMap$.insert($\pi_0, (\PrefixB, b)$) \Comment{Add $\PrefixB$ to the map}
        \State $T$.insert$(\varphi(\PrefixB))$ \Comment{Add node for $\PrefixB$ to the prefix tree}
        \State $Q$.push$(\PrefixB, b)$ \Comment{Add $\PrefixB$ to the queue}
    \EndIf
\EndFunction
\end{algorithmic}
\end{algorithm}

Mapping our algorithm to our data structures produces the following execution strategy,
which we also illustrate in Algorithms~\ref{alg:bounds} and~\ref{alg:pmap}.
%
We initialize the current best objective~$\CurrentObj$ and rule list~$\CurrentRL$.
%
While the trie contains unexplored leaves, a scheduling policy selects the next prefix~$\Prefix$
to extend; in our implementation, we pop elements from a (priority) queue, until the queue is empty.
%
Then, for every antecedent~$s$ that is not in~$\Prefix$,
we construct a new prefix~$\PrefixB$ by appending~$s$ to~$\Prefix$;
we incrementally calculate the lower bound~$b(\PrefixB, \x, \y)$,
the objective~$\Obj(\RLB, \x, \y)$, of the associated rule list~$\RLB$,
and other quantities used by our algorithm, summarized by the metadata fields of
the (potential) prefix tree node~$\varphi(\PrefixB)$.

If the objective~$\Obj(\RLB, \x, \y)$ is less than the current best objective~$\CurrentObj$,
then we update~$\CurrentObj$ and~$\CurrentRL$.
%
If the lower bound of the new prefix~$\PrefixB$ is less than the current best objective,
%\ie ${b(\Prefix', \x, \y) < \CurrentObj}$,
then as described in~\S\ref{sec:pmap}, we query the symmetry-aware map for~$\PrefixB$;
if we insert~$\Prefix'$ into the symmetry-aware map, then we also insert it into the trie and queue.
%
Otherwise, %\ie ${b(\Prefix', \x, \y) \ge \CurrentObj}$
then by our hierarchical lower bound (Theorem~\ref{thm:bound}),
no extension of~$\PrefixB$ could possibly lead to a rule list with objective
better than~$\CurrentObj$, thus we do not insert~$\PrefixB$ into the tree or queue.
%
We also leverage our other bounds from~\S\ref{sec:framework}
to aggressively prune the search space; we highlight each of these bounds
in Algorithms~\ref{alg:bounds} and~\ref{alg:pmap},
which summarize the computations and data structure operations performed in CORELS's inner loop.
%
When there are no more leaves to explore, \ie the queue is empty, we output the optimal rule list.
%
We can optionally terminate early according to some alternate condition,
\eg when the size of the prefix tree exceeds some threshold.

\subsection{Garbage collection}
\label{sec:gc}

During execution, we garbage collect the trie.
%
Each time we update the minimum objective,
we traverse the trie in a depth-first manner, deleting all subtrees
of any node with lower bound larger than the current minimum objective.
%
At other times, when we encounter a node with no children, we prune upwards,
deleting that node and recursively traversing the tree towards the root,
deleting any childless nodes.
%
This garbage collection allows us to constrain the trie's memory consumption, though in our
experiments we observe the minimum objective to decrease only a small number of times.

In our implementation, we cannot immediately delete prefix tree leaves
because each corresponds to a queue element that points to it.
%
The C++ STL priority queue is a wrapper container that prevents access to the
underlying data structure, and thus we cannot access elements in the middle of the queue,
even if we know the relevant identifying information.
%
We therefore have no way to update the queue without iterating over every element.
%
We address this by marking prefix tree leaves that we wish to delete (see~\S\ref{sec:trie}),
and delete the physical nodes lazily, after they are popped from the queue.
%
Later, in our section on experiments~(\S\ref{sec:experiments}),
we refer to two different queues that we define here: the physical queue
corresponds to the C++ queue, and thus all prefix tree leaves, and the logical queue
corresponds only to those prefix tree leaves that have not been marked for deletion.

\subsection{Custom scheduling policies}
\label{sec:scheduling}

In our setting, an ideal scheduling policy would immediately identify an optimal
rule list, and then certify its optimality by systematically eliminating the
remaining search space.
%
This motivates trying to design scheduling policies that tend to quickly find optimal rule lists.
%
When we use a priority queue to order the set of prefixes to evaluate next,
we are free to implement different scheduling policies via the ordering of
elements in the queue.
%
This motivates designing functions that assign higher priorities to `better'
prefixes that we believe are more likely to lead to optimal rule lists.
%
We follow the convention that priority queue elements are ordered
by keys, such that keys with smaller values have higher priorities.

We introduce a custom class of functions that we call \emph{curiosity} functions.
%
Broadly, we think of the curiosity of a rule list~$\RL$
as the expected objective value of another rule list~$\RL'$ that is related to~$\RL$;
different models of the relationship between~$\RL$ and~$\RL'$ lead to different
curiosity functions.
%
In general, the curiosity of~$\RL$ is by definition equal to the sum of the expected
misclassification error and the expected regularization penalty of~$\RL'$:
\begin{align}
\Curiosity(\Prefix, \x, \y) \equiv \E[ \Obj(\RL', \x, \y) ]
&= \E[\Loss(\Prefix', \Labels', \x, \y)] + \Reg \E[ K' ].
\label{eq:curiosity}
\end{align}

Next, we describe a simple curiosity function for a rule list~$\RL$ with prefix~$\Prefix$.
%
First, let~$\NCap$ denote the number of observations captured by~$\Prefix$, \ie
\begin{align}
\NCap \equiv \sum_{n=1}^N \Cap(x_n, \Prefix).
\label{eq:num-cap}
\end{align}
We now describe a model that generates another
rule list~${\RL' = (\Prefix', \Labels', \Default', K')}$ from~$\Prefix$.
%
Assume that prefix~$\Prefix'$ starts with~$\Prefix$ and captures all the data,
such that each additional antecedent in~$\Prefix'$
captures as many `new' observations as each antecedent in~$\Prefix$, on average;
then, the expected length of~$\Prefix'$ is:
\begin{align}
\E[ K' ] = \frac{N}{\NCap / K}.
\label{eq:curiosity-length}
\end{align}
Furthermore, assume that each additional antecedent in~$\Prefix'$
makes as many mistakes as each antecedent in~$\Prefix$, on average,
thus the expected misclassification error of~$\Prefix'$ is:
\begin{align}
\E[\Loss(\Prefix', \Labels', \x, \y)]
&= \E[\Loss_p(\Prefix', \Labels', \x, \y)] + \E[\Loss_0(\Prefix', \Default', \x, \y)] \nn \\
&= \E[\Loss_p(\Prefix', \Labels', \x, \y)]
=  \E[ K' ] \left(\frac{\Loss_p(\Prefix, \Labels, \x, \y)}{K}\right).
\label{eq:curiosity-error}
\end{align}
Note that the default rule misclassification error~$\Loss_0(\Prefix', \Default', \x, \y)$
is zero because we assume that~$\Prefix'$ captures all the data.
%
Combining~\eqref{eq:curiosity-length}~\eqref{eq:curiosity-error} and thus gives
curiosity for this model:
\begin{align*}
\Curiosity(\Prefix, \x, \y)
%= \E[\Loss_p(\Prefix', \Labels', \x, \y)] + \Reg \E[ K' ]
%&= \E[ K' ] \left(\frac{\Loss_p(\Prefix, \Labels, \x, \y)}{K}\right) + \Reg \E[ K' ] \\
%&=  \left(\frac{N}{\NCap / K}\right)
%  \left(\frac{\Loss_p(\Prefix, \Labels, \x, \y)}{K}\right)
%  + \Reg \left(\frac{N}{\NCap / K}\right) \nn \\
&= \left( \frac{N}{\NCap} \right) \biggl(\Loss_p(\Prefix, \Labels, \x, \y) + \Reg K \biggr) \\
&= \left( \frac{1}{N} \sum_{n=1}^N \Cap(x_n, \Prefix) \right)^{-1} b(\Prefix, \x, \y)
= \frac{b(\Prefix, \x, \y)}{\Supp(\Prefix, \x)},
\end{align*}
where for the second equality, we used the definitions of $\NCap$~\eqref{eq:num-cap}
and $\Prefix$'s lower bound~\eqref{eq:lower-bound}, and for the last equality,
we used the definition of $\Prefix$'s normalized support~\eqref{eq:support}.

The curiosity for a prefix~$\Prefix$ is thus also equal to its objective lower bound,
scaled by the inverse of its normalized support.
%
For two prefixes with the same lower bound, curiosity gives higher priority to
the one that captures more data.
%
This is a well-motivated scheduling strategy if we model prefixes that extend
the prefix with smaller support as having more `potential' to make mistakes.
%
We note that using curiosity in practice does not introduce new bit vector
or other expensive computations; during execution, we can calculate curiosity
as a simple function of already derived quantities.

In preliminary experiments, we observe that using a priority queue ordered by
curiosity sometimes yields a dramatic reduction in execution time,
compared to using a priority queue ordered by the objective lower bound.
%
Thus far, we have observed significant benefits on specific small problems,
where the structure of the solutions happen to render curiosity particularly
effective (not shown).
%
Designing and studying other `curious' functions, that are effective in more
general settings, is an exciting direction for future work.
