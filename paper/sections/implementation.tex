\section{Implementation}
\label{sec:implementation}

\input{sections/incremental}

We implement our algorithm using a collection of optimized data structures:
a trie (prefix tree), a symmetry-aware map, and a queue.
The trie acts like a cache, keeping track of rule lists we have already evaluated.
Each node in the trie contains metadata associated with that corresponding rule list;
the metadata consists of bookkeeping information such as what child rule lists are feasible and
the lower bound and accuracy for that rule list.
We also track the best observed minimum objective and its associated rule list.

The symmetry-aware map supports symmetry-aware pruning.
%
We implement this using the C++ STL unordered\_map,
% We have two different versions of the map.
to map all permutations of a set of antecedents to a key, whose value
contains the best ordering of those antecedents (\ie the prefix with the smallest lower bound).
%
Every antecedent is associated with an index, and we call the numerically
sorted order of a set of antecedents its canonical order.
%
Thus by querying a set of antecedents by its canonical order, all
permutations map to the same key.
% Keys in one version of the map represent the set of rules (in canonical order) comprising a
% rule list prefix.
% Keys in the other version represent the set of captured data points.
% The set of captured entries is identical for a given set of rules, independent of ordering, so
% different permutations still map to the same key.
%
% Note that encodings of rule lists in canonical order tend to be
% significantly smaller than encodings of captured data points,
% especially for large datasets.
%
\begin{kdd}
This map dominates memory usage for problems that explore longer prefixes.
\end{kdd}
\begin{arxiv}
The symmetry-aware map dominates memory usage for problems that explore longer prefixes.
\end{arxiv}
%
Before inserting permutation $P_i$ into the symmetry-aware map, we check
if there exists a permutation $P_j$ of $P_i$ already in the map.
If no such permutation exists, then we insert $P_i$ in the map.
Otherwise, if a permutation $P_j$ exists and the lower bound of $P_i$ is better than 
that of $P_j$, we update the map and remove $P_j$ and its subtree from the trie.
Else, if $P_j$ exists and has a better lower bound than $P_i$, we do nothing 
(\ie we do not insert $P_i$ into the symmetry-aware map or the trie).

We use a queue to store all of the leaves of the trie that still need to be explored.
%
\begin{arxiv}
We order entries in the queue to implement several different policies.
%
A first-in-first-out (FIFO) queue implements breadth-first search (BFS),
and a priority queue implements best-first search.
%
Example priority queue policies include ordering
by the lower bound, the objective, or a custom metric
that maps prefixes to real values.
\end{arxiv}
\begin{kdd}
We order entries in the queue to implement several different policies,
including breadth-first search (BFS) and best-first search.
%
For best-first we use a priority queue, ordered by either the lower bound, the objective,
or a custom priority metric.
\end{kdd}
%
In preliminary work (not shown), we also experimented with
stochastic exploration processes that don't require a queue;
instead, these follow random paths from the root to leaves.
%
Developing such methods could be an interesting direction for future work.
%
We find that ordering by the lower bound and other priority metrics
often leads to a shorter runtime than using BFS.


Mapping our algorithm to our data structures produces the following execution strategy.
%
While the trie contains unexplored leaves, a scheduling policy selects the next prefix to extend.
%
Then, for every antecedent that is not already in this prefix, we calculate the lower bound,
objective, and other metrics for the rule list formed by appending the antecedent to the prefix.
%
If the lower bound of the new rule list is less than the current minimum objective, we insert that
rule list into the symmetry-aware map, trie, and queue, and, if relevant, update the
current minimum objective.
%
If the lower bound is greater than the minimum objective,
then no extension of this rule list could possibly be optimal,
thus we do not insert the new rule list into the tree or queue.
%
We also leverage our other bounds from~\S\ref{sec:framework}
to aggressively prune the search space.

During execution, we garbage collect the trie.
%
Each time we update the minimum objective,
we traverse the trie in a depth-first manner, deleting all subtrees
of any node with lower bound larger than the current minimum objective.
%
At other times, when we encounter a node with no children, we prune upwards, deleting that
node and recursively traversing the tree towards the root, deleting any childless nodes.
%
This garbage collection allows us to constrain the trie's memory consumption, though in our
experiments we observe the minimum objective to decrease only a
\begin{kdd}
few times. \\

Our code is at \textbf{\url{https://github.com/nlarusstone/corels}}.
\end{kdd}
\begin{arxiv}
small number of times. \\

Our implementation of CORELS is at \url{https://github.com/nlarusstone/corels}.
\end{arxiv}

\begin{kdd}
\vspace{-1mm}
\end{kdd}

\begin{arxiv}
\subsection{Custom scheduling policies}

In our setting, an ideal scheduling policy would immediately identify an optimal
rule list, and then certify its optimality by systematically eliminating the
remaining search space.
%
This motivates trying to design scheduling policies that tend to quickly find optimal rule lists.
%
When we use a priority queue to order the set of prefixes to evaluate next,
we are free to implement different scheduling policies via the ordering of
elements in the queue.
%
This motivates designing functions that assign higher priorities to `better'
prefixes that we believe are more likely to lead to optimal rule lists.
%
Note that we follow the convention that priority queue elements are ordered
by keys, such that keys with smaller values correspond to higher priorities.

We introduce a custom function that we call \emph{curiosity}.
%
First, let~$\NCap$ denote the number of datapoints captured by~$\Prefix$, \ie
\begin{align}
\NCap \equiv \sum_{n=1}^N \Cap(x_n, \Prefix). \nn
\end{align}
%
Now consider a simple model for the expected objective value of a rule list
${\RL' = (\Prefix', \Labels', \Default', K')}$ generated from~$\Prefix$.
%
Assume that prefix~$\Prefix'$ starts with~$\Prefix$ and captures all the data,
such that each additional antecedent in~$\Prefix'$
both captures as many `new' datapoints and makes as many mistakes as
as each antecedent in~$\Prefix$, on average.
%
We define curiosity as the expected objective value of~$\RL'$,
which is equal to the sum of the expected prefix
misclassification error and the expected regularization penalty:
\begin{align}
\Curiosity(\Prefix, \x, \y) \equiv \E[ \Obj(\RL', \x, \y) ] &= \E[\Loss_p(\Prefix, \Labels, \x, \y)] + \E[ \Reg K' ] \nn \\
&= \E[ K' ] \left(\frac{\Loss_p(\Prefix, \Labels, \x, \y)}{K}\right) + \Reg \E[ K' ] \nn \\
&=  \left(\frac{N}{\NCap / K}\right)
  \left(\frac{\Loss_p(\Prefix, \Labels, \x, \y)}{K}\right)
  + \Reg \left(\frac{N}{\NCap / K}\right) \nn \\
&= \left( \frac{N}{\NCap} \right) \biggl(\Loss_p(\Prefix, \Labels, \x, \y) + \Reg K \biggr) \nn \\
&= \left( \frac{1}{N} \sum_{n=1}^N \Cap(x_n, \Prefix) \right)^{-1} b(\Prefix, \x, \y)
= \frac{b(\Prefix, \x, \y)}{\Supp(\Prefix, \x)}. \nn
\end{align}
%
The curiosity for a prefix~$\Prefix$ is thus also equal to its objective lower bound,
scaled by the inverse of its normalized support.
%
For two prefixes with the same lower bound, curiosity gives higher priority to
the one that captures more data.
%
This is a well-motivated scheduling strategy if we model prefixes that extend
the prefix with smaller support as having more `potential' to make mistakes.
%
We note that using curiosity in practice does not introduce new bit vector
or other expensive computations; during execution, we can calculate curiosity
as a simple function of already derived quantities.

In preliminary experiments, we observe that using a priority queue ordered by
curiosity sometimes yields a dramatic reduction in execution time,
compared to using a priority queue ordered by the objective lower bound.
%
Thus far, we have observed significant benefits on specific small problems,
where the structure of the solutions happen to render curiosity particularly
effective (not shown).
%
Designing and studying other `curious' functions, that are effective in more
general settings, is an exciting direction for future work.
\end{arxiv}
