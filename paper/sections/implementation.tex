\section{Implementation}
\label{sec:implementation}

We implement our algorithm using a collection of optimized data structures:
a trie, a symmetry-aware map, and a queue.
The trie acts like a cache, keeping track of rule lists we have already evaluated.
Each node in the trie contains metadata associated with that corresponding rule list;
the metadata consists of bookkeeping information such as what child rule lists are feasible and
the lower bound and accuracy for that rule list.
The trie also tracks the best observed rule list by keeping track of the minimum objective
found and its associated rule list.

We implement the symmetry-aware map using the C++ STL unordered\_map, which
% Since we are not yet doing anything with the capture-based representation, we shouldn't
% discuss it as we won't be showing performance.
% We have two different versions of the map.
% Both versions 
maps all permutations of a set of rules to a key, whose value
contains the best ordering of those rules (i.e., the one with the smallest objective).
Every rule has a rule id number, and we call the numerically sorted order of a set of rules its
canonical order, thus, by quering a set of rules by its canonical order, all
permutations map to the same key.
% Keys in one version of the map represent the set of rules (in canonical order) comprising a
% rule list prefix.
% Keys in the other version represent the set of captured data points.
% The set of captured entries is identical for a given set of rules, independent of ordering, so
% different permutations still map to the same key.
%
Note that encodings of rule lists in canonical order tend to be
significantly smaller than encodings of captured data points,
especially for large datasets.
%
In general, the symmetry-aware map dominates memory usage during long runs.
Before inserting permutation $P<sub>i</sub>$ into the symmetry-aware map, we check
if there exists a permutation $P<sub>j</sub>$ of $P<sub>i</sub>$ alread in the map.
If the objective of $P<sub>i</sub>$ is better than the objective of $P<sub>j</sub>$,
we update the map and remove $P<sub>j</sub>$ and its subtree from the trie.
Otherwise we do nothing (i.e., we do not insert $P<sub>i</sub>$ into the symmetry-aware map
or the trie.

We use a queue to store all of the leaves of the trie that still need to be explored.
We order entries in the queue to implement several different scheduling policies,
including BFS, DFS, and a priority queue, ordered by the lower bound, the objective, or the
curiosity.
We also have a stochastic exploration process that bypasses the use of a queue by walking
the trie, randomly choosing a child each time, until encountering a leaf.
We find that ordering by curiosity often leads to a shorter runtime than using BFS.

Mapping our algorithm to our data structures produces the following execution strategy.
While there are still leaves of the trie to be explored, use the scheduling policy to select
the next rule list to evaluate.
Then, for every rule that is not already in this rule list, we calculate the lower bound,
objective, and other metrics produced if the rule were appended to the rule list.
If the new rule list produces a lower bound less than the current minimum objective, we insert that
rule list into the symmetry-aware map, the tree, and the queue and, if necessary, update the
current minimum objective.
If the lower bound is greater than the minimum objective, meaning this new rule list is never
better than one we have already seen, we do not insert the new rule list into the tree or queue. 

Each time we update the minimum objective, we garbage collect the trie, by walking it
from the root the leaves, deleting any subtrees of nodes with a lower bound larger than the current
minimum objective. If we encounter a node with no children, we prune upwards--deleting that
node and recursively traversing the tree towards the root, deleting any childless nodes.
This garbage collection allows us to constrain the trie's memory consumption, though in our
experiments we observe the minimum objective to decrease only a small number of times.

%\section{Implementation architecture}
%
%We present an architecture for executing our branch-and-bound algorithm,
%consisting of a cache, a queue that is associated with a search policy,
%and, optionally, a symmetry-aware map.
%%
%First, we describe the cache, our primary data structure~(\S\ref{sec:cache});
%it is organized as a prefix tree and supports the incremental computations,
%detailed in~\S\ref{sec:incremental}, that are central to our approach.
%%
%Second, we describe the queue and search policy~(\S\ref{sec:queue}).
%%
%Like the queue in Algorithm~\ref{alg:branch-and-bound},
%our queue keeps track of which prefixes to evaluate during execution.
%%
%The policy for selecting a prefix from the queue to evaluate next,
%and thus also the natural queue data structure, depend on
%the search policy employed for exploring the space of rule lists
%%
%Next, we describe the symmetry-aware map~(\S\ref{sec:map}),
%which enables garbage collection of prefixes eliminated by the
%equivalent support bound in Theorem~\ref{sec:equivalent}.
%%
%While we present the map as an optional component of our architecture,
%our calculations in~\S\ref{sec:permutation-counting}
%and experiments in~\S\ref{sec:experiments} demonstrate that
%it is critical for efficient and practical algorithm performance.
%%
%Finally, we summarize an artifact we implemented~(\S\ref{sec:system}),
%which we evaluate in~\S\ref{sec:experiments}.
%
%\subsection{Prefix tree cache for incremental computation}
%\label{sec:cache}
%
%We maintain a cache to support incremental computation.
%%
%Our cache is organized as a prefix tree, which is also known as a trie.
%%
%
%\subsection{Queue and search policies}
%\label{sec:queue}
%
%Different search policies suggest different natural queue data structures.
%
%\begin{itemize}
%\item breadth-first
%\item depth-first
%\item something based on greedy
%\item (curiosity, lower bound, optimization) $\times$ (priority queue, something like Thompson sampling)
%\item optimistic
%\end{itemize}
%
%\subsection{Map data structure for symmetry-aware garbage collection}
%\label{sec:map}
%
%%\subsection{Large-scale optimization}
%
%\subsection{System}
%\label{sec:system}
