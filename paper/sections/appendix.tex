\section*{Appendix A. Excessive antecedent support}

\begin{theorem}[Upper bound on antecedent support]
\label{thm:ub-support}
Let ${\OptimalRL = (\Prefix, \Labels, \Default, K)}$
be any optimal rule list with objective~$\OptimalObj$, \ie
${\OptimalRL \in \argmin_\RL \Obj(\RL, \x, \y)}$,
and let ${\Prefix = (p_1, \dots, p_{k-1},}$
${p_k, \dots, p_K)}$ be its prefix.
%
For each ${k \le K}$, antecedent~$p_k$ in~$\Prefix$
has support less than or equal to
the fraction of all data not captured by preceding antecedents,
by an amount greater than the regularization parameter~$\Reg$:
\begin{align}
\Supp(p_k, \x \given \Prefix) \le 1 - \Supp(\Prefix^{k-1}, \x) - \Reg,
\label{eq:ub-support}
\end{align}
where ${\Prefix^{k-1} = (p_1, \dots, p_{k-1})}$.
%
For the last antecedent, \ie when ${p_k = p_K}$, equality implies
that there also exists a shorter optimal rule list
${\RL' = (\Prefix^{K-1}, \Labels', \Default', K - 1) \in}$ ${\argmin_\RL \Obj(\RL, \x, \y)}$.
%with prefix~$\Prefix^{K-1}$.
\end{theorem}

\begin{proof}
First, we focus on the last antecedent~$p_{K+1}$ in a rule list~$\RL'$.
%
Let ${\RL = (\Prefix, \Labels, \Default, K)}$
be a rule list with prefix ${\Prefix = (p_1, \dots, p_K)}$
and objective ${\Obj(\RL, \x, \y) \ge \OptimalObj}$, where
${\OptimalObj \equiv}$ ${\min_{\RLB} \Obj(\RLB, \x, \y)}$
is the optimal objective.
%
Let ${\RL' = (\Prefix', \Labels', \Default', K + 1)}$
be a rule list whose prefix ${\Prefix' = (p_1, \dots, p_K, p_{K+1})}$
starts with~$\Prefix$ and ends with a new antecedent~$p_{K+1}$.
%
Suppose~$p_{K+1}$ in the context of~$\Prefix'$ captures nearly all
data not captured by~$\Prefix$, except for a fraction~$\epsilon$
upper bounded by the regularization parameter~$\Reg$:
\begin{align*}
1 - \Supp(\Prefix, \x) - \Supp(p_{K+1}, \x \given \Prefix') \equiv \epsilon \le \Reg.
\end{align*}
%
Since~$\Prefix'$ starts with~$\Prefix$,
its prefix misclassification error is at least as great;
the only discrepancy between the misclassification errors
of~$\RL$ and~$\RL'$ can come from the difference between the support of
the set of data not captured by~$\Prefix$ and the support of~$p_{K+1}$:
\begin{align*}
| \Loss(\RL', \x, \y) - \Loss(\RL, \x, \y) | \le
1 - \Supp(\Prefix, \x) - \Supp(p_{K+1}, \x \given \Prefix') = \epsilon.
\end{align*}
The best outcome for~$\RL'$ would occur if its misclassification
error were smaller than that of~$\RL$ by~$\epsilon$,
%\eg this could happen if all data not captured by~$\Prefix'$
%had the same class label, in which case the default rule of~$\RL'$
%would incur zero misclassification error.
% --> it's more complicated, would need to discuss minority class label, etc.
%
therefore
\begin{align*}
\Obj(\RL', \x, \y) &= \Loss(\RL', \x, \y) + \Reg (K+1) \\
&\ge \Loss(\RL, \x, \y) - \epsilon + \Reg(K+1)
= \Obj(\RL, \x, \y) - \epsilon + \Reg \ge \Obj(\RL, \x, \y) \ge \OptimalObj.
\end{align*}
$\RL'$ is an optimal rule list,
\ie ${\RL' \in \argmin_{\RLB} \Obj(\RLB, \x, y)}$,
if and only if ${\Obj(\RL', \x, \y) = \Obj(\RL, \x, \y) =}$ ${\OptimalObj}$,
which requires ${\epsilon = \Reg}$.
%
Otherwise, ${\epsilon < \Reg}$, in which case
\begin{align*}
\Obj(\RL', \x, \y) \ge \Obj(\RL, \x, \y) - \epsilon + \Reg
> \Obj(\RL, \x, \y) \ge \OptimalObj,
\end{align*}
therefore $\RL'$ is not optimal, \ie  ${\RL' \notin \argmin_{\RLB} \Obj(\RLB, \x, \y)}$.
%
This demonstrates the desired result for ${k = K}$.

In the remainder, we prove the bound in~\eqref{eq:ub-support} by contradiction,
in the context of a rule list~$\RL''$.
%
Let~$\RL$ and~$\RL'$ retain their definitions from above,
thus as before, that the data not captured by~$\Prefix'$
has normalized support~${\epsilon \le \Reg}$, \ie
\begin{align*}
1 - \Supp(\Prefix', \x) = 1 - \Supp(\Prefix, \x) - \Supp(p_{K+1}, \x \given \Prefix') = \epsilon \le \Reg.
\end{align*}
Thus for any rule list~$\RL''$ whose prefix
$\Prefix'' = (p_1, \dots, p_{K+1}, \dots, p_{K'})$ starts
with~$\Prefix'$ and ends with one or more additional rules,
each additional rule~$p_k$ has support
${\Supp(p_k, \x \given \Prefix'') \le}$ ${\epsilon \le \Reg}$,
for all~${k > K+1}$.
%
By Theorem~\ref{thm:min-capture},
all of the additional rules have insufficient support,
therefore~$\Prefix''$ cannot be optimal,
\ie ${\RL'' \notin \argmin_{\RLB} \Obj(\RLB, \x, \y)}$.
\end{proof}

Similar to Theorem~\ref{thm:min-capture}, our lower bound on
antecedent support, we can apply Theorem~\ref{thm:ub-support}
in the contexts of both constructing rule lists and
rule mining~(\S\ref{sec:setup}).
%
Theorem~\ref{thm:ub-support} implies that if we only seek a single
optimal rule list, then during branch-and-bound execution,
we can prune a prefix if we ever add an antecedent with support
too similar to the support of the set of data not captured by the
preceding antecedents.
%
One way to view this result is that if
${\RL = (\Prefix, \Labels, \Default, K)}$
and ${\RL' = (\Prefix', \Labels', \Default', K + 1)}$
are rule lists such that~$\Prefix'$ starts with~$\Prefix$
and ends with an antecedent that captures all or nearly all
data not captured by~$\Prefix$, then the new rule in~$\RL'$
behaves similar to the default rule of~$\RL$.
%
As a result, the misclassification error of~$\RL'$ must be
similar to that of~$\RL$, and any reduction may not be
sufficient to offset the penalty for longer prefixes.

\begin{proposition}[Excessive antecedent support propagates]
\label{prop:ub-support}
Define~$\StartContains(\Prefix)$ as in~\eqref{eq:start-contains},
and let ${\Prefix = (p_1, \dots, p_{K})}$ be a prefix,
such that its last antecedent~$p_{K}$ has excessive support,
\ie the opposite of the bound in~\eqref{eq:ub-support}:
\begin{align*}
\Supp(p_K, \x \given \Prefix) > 1 - \Supp(\Prefix^{K-1}, \x) - \Reg,
\end{align*}
where ${\Prefix^{K-1} = (p_1, \dots, p_{K-1})}$.
%
Let ${\RLB = (\PrefixB, \LabelsB, \DefaultB, \kappa)}$
be any rule list with prefix
${\PrefixB =}$ ${(P_1, \dots, P_{\kappa})}$
such that~$\PrefixB$ starts with ${\PrefixB^{K'-1} =}$
${(P_1, \dots, P_{K'-1}) \in \StartContains(\Prefix^{K-1})}$
and~${P_{K'} = p_{K}}$.
%
It follows that~$P_{K'}$ has excessive support in prefix~$\PrefixB$,
and furthermore, ${\RLB \notin \argmin_{\RL} \Obj(\RL, \x, \y)}$.
\end{proposition}

\begin{proof}
Since ${\PrefixB^{K'} = (P_1, \dots, P_{K'})}$
contains all the antecedents in~$\Prefix$, we have that
\begin{align*}
\Supp(\PrefixB^{K'}, \x) \ge \Supp(\Prefix, \x).
\end{align*}
Expanding these two terms gives
\begin{align*}
\Supp(\PrefixB^{K'}, \x)
&= \Supp(\PrefixB^{K'-1}, \x) + \Supp(P_{K'}, \x \given \PrefixB) \\
&\ge \Supp(\Prefix, \x)
= \Supp(\Prefix^{K-1}, \x) + \Supp(p_K, \x \given \Prefix)
> 1 - \Reg.
\end{align*}
Rearranging gives
\begin{align*}
\Supp(P_{K'}, \x \given \PrefixB)
> 1 - \Supp(\PrefixB^{K'-1}, \x) - \Reg,
\end{align*}
thus~$P_{K'}$ has excessive support in~$\PrefixB$.
%
By Theorem~\ref{thm:ub-support},
${\RLB \notin \argmin_{\RL} \Obj(\RL, \x, \y)}$.
\end{proof}

\section*{Appendix B. Proof of Theorem~\ref{thm:similar} (Similar support bound)}

We begin by defining four related rule lists.
%
First, let ${\RL = (\Prefix, \Labels, \Default, K)}$
be a rule list with prefix ${\Prefix = (p_1, \dots, p_K)}$
and labels ${\Labels = (q_1, \dots, q_K)}$.
%
Second, let ${\RLB = (\PrefixB, \LabelsB, \DefaultB, \kappa)}$
be a rule list with prefix ${\PrefixB = (P_1, \dots, P_\kappa)}$
and labels ${\LabelsB = (Q_1, \dots, Q_\kappa)}$.
%
Define~$\omega$ as in~\eqref{eq:omega}
and~$\Omega$ as in~\eqref{eq:big-omega},
and require that~${\omega, \Omega \le \Reg}$.
%
Third, let ${\RL' = (\Prefix', \Labels', \Default', K') \in}$
${\StartsWith(\Prefix)}$ be any rule list
whose prefix starts with~$\Prefix$, such that~${K' \ge K}$.
%
Denote the prefix and labels of~$\RL'$ by
${\Prefix' = (p_1, \dots, p_K, p_{K+1}, \dots, p_{K'})}$
and ${\Labels = (q_1, \dots, q_{K'})}$,
respectively.
%
Finally, define
${\RLB' = (\PrefixB', \LabelsB', \DefaultB', \kappa') \in \StartsWith(\PrefixB)}$
to be the `analogous' rule list, \ie whose prefix
${\PrefixB' =}$ ${(P_1, \dots, P_\kappa, P_{\kappa+1}, \dots, P_{\kappa'})
= (P_1, \dots, P_\kappa, p_{K+1}, \dots, p_{K'})}$
starts with~$\PrefixB$ and ends with the same ${K'-K}$
antecedents as~$\Prefix'$.
%
Let ${\LabelsB' = (Q_1, \dots, Q_{\kappa'})}$
denote the labels of~$\RLB'$.

%Suppose that the lower bounds of~$\Prefix$ and~$\PrefixB$
%obey ${b(\Prefix, \x, \y) < b(\PrefixB, \x, \y)}$.
%
The smallest possible objective for~$\RLB'$, in relation
to the objective of~$\RL'$, reflects both the difference
between the objective lower bounds of~$\RLB$ and~$\RL$
and the largest possible discrepancy between the
objectives of~$\RL'$ and~$\RLB'$.
%
The latter would occur if~$\RL'$ misclassified all the data
corresponding to both~$\omega$ and~$\Omega$ while~$\RLB'$
correctly classified this same data, thus
\begin{align}
\Obj(\RLB', \x, \y) \ge \Obj(\RL', \x, \y)
  + b(\PrefixB, \x, \y) - b(\Prefix, \x, \y) - \omega - \Omega.
\label{eq:similar-analogous}
\end{align}
%
Now let~$\RLB^*$ be an optimal rule list with prefix
constrained to start with~$\PrefixB$,
\begin{align*}
\RLB^* \in \argmin_{\RLB^\dagger \in \StartsWith(\PrefixB)} \Obj(\RLB^\dagger, \x, \y),
\end{align*}
and let~$\kappa^*$ be the length of~$\RLB^*$.
%
Also let~$\RL^*$ be the analogous $K^*$-rule list whose prefix
starts with~$\Prefix$ and ends with the same~${\kappa^* - \kappa}$
antecedents as~$\RLB^*$, where~${K^* = K + \kappa^* - \kappa}$.
%
By~\eqref{eq:similar-analogous},
\begin{align*}
\min_{\RLB^\dagger \in \StartsWith(\PrefixB)} \Obj(\RLB^\dagger, \x, \y)
&= \Obj(\RLB^*, \x, \y) \\
&\ge \Obj(\RL^*, \x, \y)
  + b(\PrefixB, \x, \y) - b(\Prefix, \x, \y) - \omega - \Omega \\
&\ge \min_{\RL^\dagger \in \StartsWith(\Prefix)} \Obj(\RL^\dagger, \x, \y)
  + b(\PrefixB, \x, \y) - b(\Prefix, \x, \y) - \omega - \Omega.
\end{align*}

\section*{Appendix C. Data processing details and antecedent mining}

\textbf{ProPublica recidivism dataset}
Table~\ref{tab:recidivism-data} shows the 7 attributes
and corresponding 19 categorical values
that we use for the ProPublica dataset.
%
From these, we construct 19 single-clause antecedents, \eg ${(age = 23-25)}$.
%
We then combine pairs of these antecedents as conjunctions to form
two-clause antecedents, \eg ${(age = 23-25) \wedge (priors = 2-3)}$.
%
By virtue of our lower bound on antecedent support,
(Theorem~\ref{thm:min-capture},~\S\ref{sec:lb-support}),
we eliminate antecedents with support less than 0.005 or greater than 0.995,
since ${\Reg = 0.005}$ is the smallest regularization parameter value
we study for this problem.
%
With this filtering step, we generate between 155 and 157 antecedents
for each fold; without it, we would instead generate 361 antecedents --
more than twice as many -- as input to our algorithm.

\begin{table}[h!]
\centering
%$Q_\text{max}$ $K_\text{max}$
\begin{tabular}{l  | c  c  c}
Feature & Value range & Categorical values & Count \\
\hline
sex & --- & male, female & 2 \\
age & 18-96 & 18-20, 21-22, 23-25, 26-45, $>$45  & 5 \\
juvenile felonies & 0-20 & 0, $>$0 & 2 \\
juvenile misdemeanors & 0-13 & 0, $>$0 & 2 \\
%other juvenile crimes & 0-17 & --- & 2 \\
juvenile crimes & 0-21 & 0, $>$0 & 2 \\
priors & 0-38 & 0, 1, 2-3, $>$3 & 4 \\
current charge & --- & misdemeanor, felony & 2
\end{tabular}
%\vspace{4mm}
\caption{Categorical features (7 attributes, 19 values) from the ProPublica dataset.
We construct the feature \emph{juvenile crimes} from the sum of
\emph{juvenile felonies}, \emph{juvenile misdemeanors}, and
the number of juvenile crimes that were neither felonies nor misdemeanors (not shown).
}
\vspace{4mm}
\label{tab:recidivism-data}
\end{table}

\textbf{NYCLU stop-and-frisk dataset.} The original dataset contains 45,787 records,
each describing an incident involving a stopped person; the individual
was frisked in 30,345 (66.3\%) of records and and searched in 7,283 (15.9\%).
%
In 30,961 records, the individual was frisked and/or searched (67.6\%); of those,
a criminal possession of a weapon was identified 1,445 times (4.7\% of these records).
%
We remove 1,929 records with missing data, as well as a small number with extreme values
for the individual's age -- we eliminate those with age~${< 12}$ or~${>89}$.
%we also assume that one age marked `366' is a typo, and we replace it with `36'.
%
This yields a set of 29,595 records in which the individual was frisked and/or searched.
%
To address the class imbalance for this problem, we sample records from the
smaller class with replacement.
%
We generate cross-validation folds first, and then resample within each fold.
%
In our 10-fold cross-validation experiments, each training set contains 50,743 datapoints.

Table~\ref{tab:frisk-data} shows the 5 categorical attributes that we use,
corresponding to a total of 28 values.
%
Our results in~\S\ref{sec:examples} through~\S\ref{sec:sparsity}
are from experiments that use 28 single-clause antecedents corresponding
these 28 values, \eg (\emph{stop reason = suspicious object}).
%
Our experiments in~\S\ref{sec:traces} use the same antecedents,
as well as negations of the 18 antecedents corresponding to the two features
\emph{stop reason} and \emph{additional circumstances},
which gives a total of 46 antecedents.

\begin{table}[h!]
\centering
%$Q_\text{max}$ $K_\text{max}$
\begin{tabular}{l | c  c}
Feature & Values & Count \\
\hline
stop reason & suspicious object, fits description, casing, & 9 \\
& acting as lookout, suspicious clothing, & \\
& drug transaction, furtive movements, & \\
& actions of violent crime, suspicious bulge \\
\hline
additional & proximity to crime scene, evasive response,  & 9 \\
circumstances & associating with criminals, changed direction, & \\
& high crime area, time of day,  & \\
& sights and sounds of criminal activity, & \\
& witness report, ongoing investigation & \\
\hline
city & Queens,  Manhattan, Brooklyn, Staten, Bronx & 5 \\
\hline
location & housing authority, transit authority, & 3 \\
& neither housing nor transit authority & \\
\hline
inside or outside & inside, outside & 2 \\
\end{tabular}
%\vspace{4mm}
\caption{Categorical features (5 attributes, 28 values) from the NYCLU dataset.}
\vspace{4mm}
\label{tab:frisk-data}
\end{table}

\section*{Appendix D. Example optimal rule lists, for different values of~$\Reg$}

For each of our prediction problems, we provide listings of
optimal rule lists found by CORELS, across 10 cross-validation folds,
for different values of the regularization parameter~$\Reg$.
%
These rule lists correspond to the results for CORELS summarized
in Figure~\ref{fig:sparsity}~(\S\ref{sec:sparsity}).
%
Recall that as~$\Reg$ decreases, optimal rule lists tend to grow in length. \\

\textbf{ProPublica recidivism dataset.}
We show example optimal rule lists that predict two-year recidivism.
%
Figure~\ref{fig:recidivism-rule-list-02-01} shows examples for
regularization parameters~${\Reg = 0.02}$ and~0.01;
we showed examples for~${\Reg = 0.005}$ in
Figure~\ref{fig:recidivism-all-folds}~(\S\ref{sec:examples}) .

For the largest regularization parameter~${\Reg = 0.02}$~(Figure~\ref{fig:recidivism-rule-list-02-01}),
we observe that all folds identify the same length-1 rule list.
%
For the smallest value~${\Reg = 0.005}$~(Figure~\ref{fig:recidivism-all-folds}),
we observed in~\S\ref{sec:examples} that the folds identify three different
optimal rule lists that all contain the same prefix rules, up to a permutation.
%
Across all three regularization parameter values and all folds,
the prefix rules always predict the positive class label,
and the default rule always predicts the negative class label.
%
We note that our objective is not designed to enforce any of these properties,
though some may be seen as desirable.
%
With the intermediate~${\Reg = 0.01}$ (Figure~\ref{fig:recidivism-all-folds},~\S\ref{sec:examples}),
we observe a greater diversity of optimal rule lists, though they share similar structure.

%compas 0.02
%{priors:>3}~1;default~0
%
%compas 0.01
%{sex:Male,juvenile-crimes:>0}~1;{priors:>3}~1;default~0
%{age:23-25,priors:2-3}~1;{age:18-20}~1;{sex:Male,age:21-22}~1;{priors:>3}~1;default~0
%{sex:Male,juvenile-crimes:>0}~1;{juvenile-felonies:=0,priors:>3}~1;default~0
%{age:23-25,priors:2-3}~1;{age:18-20}~1;{sex:Male,age:21-22}~1;{priors:>3}~1;default~0
%{sex:Male,juvenile-crimes:>0}~1;{priors:>3}~1;default~0
%{age:23-25,priors:2-3}~1;{age:18-20}~1;{sex:Male,age:21-22}~1;{priors:>3}~1;default~0
%{age:18-20}~1;{sex:Male,age:21-22}~1;{priors:>3}~1;default~0
%{age:23-25,priors:2-3}~1;{age:18-20}~1;{priors:>3}~1;{sex:Male,age:21-22}~1;default~0
%{age:18-20}~1;{priors:>3}~1;default~0
%{age:18-20}~1;{sex:Male,age:21-22}~1;{priors:>3}~1;default~0
\begin{figure}[h!]
\textbf{Two-year recidivism prediction $(\Reg = 0.02)$}
\vspace{1mm}
\begin{algorithmic}
\State \bif $(priors > 3)$ \bthen $yes$ \Comment{Found by all 10 folds}
\State \belse $no$
\end{algorithmic}
\vspace{5mm}
\textbf{Two-year recidivism prediction $(\Reg = 0.01)$}
\vspace{1mm}
\begin{algorithmic}
\State \bif $(age = 23-25) \band (priors = 2-3)$ \bthen $yes$ \Comment{Found by 3 folds}
\State \belif $(age = 18-20)$ \bthen $yes$
\State \belif $(sex = male) \band (age = 21-22)$ \bthen $yes$
\State \belif $(priors > 3)$ \bthen $yes$
\State \belse $no$
\end{algorithmic}
\vspace{1mm}
\begin{algorithmic}
\State \bif $(age = 23-25) \band (priors = 2-3)$ \bthen $yes$ \Comment{Found by 1 fold}
\State \belif $(age = 18-20)$ \bthen $yes$
\State \belif $(priors > 3)$ \bthen $yes$
\State \belif $(sex = male) \band (age = 21-22)$ \bthen $yes$
\State \belse $no$
\end{algorithmic}
\vspace{1mm}
\begin{algorithmic}
\State \bif $(age = 18-20)$ \bthen $yes$ \Comment{Found by 2 folds}
\State \belif $(sex = male) \band (age = 21-22)$ \bthen $yes$
\State \belif $(priors > 3)$ \bthen $yes$
\State \belse $no$
\end{algorithmic}
\vspace{1mm}
\begin{algorithmic}
\State \bif $(age = 18-20)$ \bthen $yes$ \Comment{Found by 1 fold}
\State \belif $(priors > 3)$ \bthen $yes$
\State \belse $no$
\end{algorithmic}
\vspace{1mm}
\begin{algorithmic}
\State \bif $(sex = male) \band (juvenile~crimes > 0)$ \bthen $yes$ \Comment{Found by 2 folds}
\State \belif $(priors > 3)$ \bthen $yes$
\State \belse $no$
\end{algorithmic}
\vspace{1mm}
\begin{algorithmic}
\State \bif $(sex = male) \band (juvenile~crimes > 0)$ \bthen $yes$ \Comment{Found by 1 fold}
\State \belif $(juvenile~felonies = 0) \band (priors > 3)$ \bthen $yes$
\State \belse $no$
\end{algorithmic}
\caption{Example optimal rule lists for the ProPublica dataset,
found by CORELS with regularization parameters~${\Reg = 0.02}$~(top),
and~0.01~(bottom) across 10 cross-validation folds.
}
\label{fig:recidivism-rule-list-02-01}
\end{figure}

\textbf{NYCLU stop-and-frisk dataset.}
We show example optimal rule lists that predict whether a weapon
will be found on a stopped individual who is frisked or searched.
%
Figure~\ref{fig:weapon-rule-list-04-01} shows
regularization parameters~${\Reg = 0.04}$ and~0.01,
and Figure~\ref{fig:weapon-rule-list-0025} shows~${\Reg = 0.0025}$.

For each of the two larger regularization parameters in Figure~\ref{fig:weapon-rule-list-04-01},
${\Reg = 0.04}$~(top) and 0.01~(bottom), we observe that across the folds,
all the optimal rule lists contain the same prefix rules, up to a permutation.
%
Furthermore, the prefix rules always predict the positive class label,
and the default rule always predicts the negative class label.
%
We note that our objective is not designed to enforce any of these properties,
though some may be seen as desirable.
%
With the smaller regularization parameter~${\Reg = 0.0025}$ (Figure~\ref{fig:weapon-rule-list-0025}), we observe a greater diversity
of optimal rule lists, though they share similar structure.

%frisk 0.04
%{cs_bulge:stop-reason=suspicious-bulge}~1;{cs_objcs:stop-reason=suspicious-object}~1;default~0
%{cs_objcs:stop-reason=suspicious-object}~1;{cs_bulge:stop-reason=suspicious-bulge}~1;default~0
%{cs_objcs:stop-reason=suspicious-object}~1;{cs_bulge:stop-reason=suspicious-bulge}~1;default~0
%{cs_objcs:stop-reason=suspicious-object}~1;{cs_bulge:stop-reason=suspicious-bulge}~1;default~0
%{cs_bulge:stop-reason=suspicious-bulge}~1;{cs_objcs:stop-reason=suspicious-object}~1;default~0
%{cs_bulge:stop-reason=suspicious-bulge}~1;{cs_objcs:stop-reason=suspicious-object}~1;default~0
%{cs_objcs:stop-reason=suspicious-object}~1;{cs_bulge:stop-reason=suspicious-bulge}~1;default~0
%{cs_objcs:stop-reason=suspicious-object}~1;{cs_bulge:stop-reason=suspicious-bulge}~1;default~0
%{cs_objcs:stop-reason=suspicious-object}~1;{cs_bulge:stop-reason=suspicious-bulge}~1;default~0
%{cs_objcs:stop-reason=suspicious-object}~1;{cs_bulge:stop-reason=suspicious-bulge}~1;default~0
%
%frisk 0.01
%{cs_bulge:stop-reason=suspicious-bulge}~1;{location:transit-authority}~1;{cs_objcs:stop-reason=suspicious-object}~1;default~0
%{cs_objcs:stop-reason=suspicious-object}~1;{location:transit-authority}~1;{cs_bulge:stop-reason=suspicious-bulge}~1;default~0
%{location:transit-authority}~1;{cs_bulge:stop-reason=suspicious-bulge}~1;{cs_objcs:stop-reason=suspicious-object}~1;default~0
%{cs_bulge:stop-reason=suspicious-bulge}~1;{location:transit-authority}~1;{cs_objcs:stop-reason=suspicious-object}~1;default~0
%{location:transit-authority}~1;{cs_objcs:stop-reason=suspicious-object}~1;{cs_bulge:stop-reason=suspicious-bulge}~1;default~0
%{location:transit-authority}~1;{cs_objcs:stop-reason=suspicious-object}~1;{cs_bulge:stop-reason=suspicious-bulge}~1;default~0
%{cs_objcs:stop-reason=suspicious-object}~1;{location:transit-authority}~1;{cs_bulge:stop-reason=suspicious-bulge}~1;default~0
%{cs_objcs:stop-reason=suspicious-object}~1;{location:transit-authority}~1;{cs_bulge:stop-reason=suspicious-bulge}~1;default~0
%{cs_objcs:stop-reason=suspicious-object}~1;{cs_bulge:stop-reason=suspicious-bulge}~1;{location:transit-authority}~1;default~0
%{location:transit-authority}~1;{cs_objcs:stop-reason=suspicious-object}~1;{cs_bulge:stop-reason=suspicious-bulge}~1;default~0
\begin{figure}[h!]
\textbf{Weapon prediction $(\Reg = 0.04)$}
\vspace{1mm}
\begin{algorithmic}
\State \bif $(stop~reason = suspicious~object)$ \bthen $yes$ \Comment{Found by 7 folds}
\State \belif $(stop~reason = suspicious~bulge)$ \bthen $yes$
\State \belse $no$
\end{algorithmic}
\vspace{1mm}
\begin{algorithmic}
\State \bif $(stop~reason = suspicious~bulge)$ \bthen $yes$ \Comment{Found by 3 folds}
\State \belif $(stop~reason = suspicious~object)$ \bthen $yes$
\State \belse $no$
\end{algorithmic}
\vspace{5mm}
\textbf{Weapon prediction $(\Reg = 0.01)$}
\vspace{1mm}
\begin{algorithmic}
\State \bif $(location = transit~authority)$ \bthen $yes$ \Comment{Found by 3 folds}
\State \belif $(stop~reason = suspicious~object)$ \bthen $yes$
\State \belif $(stop~reason = suspicious~bulge)$ \bthen $yes$
\State \belse $no$
\end{algorithmic}
\vspace{1mm}
\begin{algorithmic}
\State \bif $(stop~reason = suspicious~object)$ \bthen $yes$ \Comment{Found by 3 folds}
\State \belif $(location = transit~authority)$ \bthen $yes$
\State \belif $(stop~reason = suspicious~bulge)$ \bthen $yes$
\State \belse $no$
\end{algorithmic}
\vspace{1mm}
\begin{algorithmic}
\State \bif $(stop~reason = suspicious~bulge)$ \bthen $yes$ \Comment{Found by 2 folds}
\State \belif $(location = transit~authority)$ \bthen $yes$
\State \belif $(stop~reason = suspicious~object)$ \bthen $yes$
\State \belse $no$
\end{algorithmic}
\vspace{1mm}
\begin{algorithmic}
\State \bif $(location = transit~authority)$ \bthen $yes$ \Comment{Found by 1 fold}
\State \belif $(stop~reason = suspicious~bulge)$ \bthen $yes$
\State \belif $(stop~reason = suspicious~object)$ \bthen $yes$
\State \belse $no$
\end{algorithmic}
\vspace{1mm}
\begin{algorithmic}
\State \bif $(stop~reason = suspicious~object)$ \bthen $yes$ \Comment{Found by 1 fold}
\State \belif $(stop~reason = suspicious~bulge)$ \bthen $yes$
\State \belif $(location = transit~authority)$ \bthen $yes$
\State \belse $no$
\end{algorithmic}
\caption{Example optimal rule lists for the NYCLU stop-and-frisk dataset,
found by CORELS with regularization parameters~${\Reg = 0.04}$~(top) and~0.01~(bottom),
across 10 cross-validation folds.
}
\label{fig:weapon-rule-list-04-01}
\end{figure}

%frisk 0.025
%{cs_objcs:stop-reason=suspicious-object}~1;{cs_casng:stop-reason=casing}~0;{cs_bulge:stop-reason=suspicious-bulge}~1;{cs_descr:stop-reason=fits-description}~0;{location:transit-authority}~1;{inout:inside}~0;{city:Manhattan}~1;default~0
%{cs_objcs:stop-reason=suspicious-object}~1;{cs_bulge:stop-reason=suspicious-bulge}~1;{location:housing-authority}~0;{cs_descr:stop-reason=fits-description}~0;{cs_casng:stop-reason=casing}~0;{city:Manhattan}~1;default~0
%{cs_drgtr:stop-reason=drug-transaction}~0;{cs_bulge:stop-reason=suspicious-bulge}~1;{cs_objcs:stop-reason=suspicious-object}~1;{location:housing-authority}~0;{cs_descr:stop-reason=fits-description}~0;{cs_casng:stop-reason=casing}~0;{city:Manhattan}~1;{city:Bronx}~1;default~0
%{cs_objcs:stop-reason=suspicious-object}~1;{cs_casng:stop-reason=casing}~0;{cs_bulge:stop-reason=suspicious-bulge}~1;{cs_descr:stop-reason=fits-description}~0;{location:transit-authority}~1;{inout:inside}~0;{city:Manhattan}~1;default~0
%{cs_objcs:stop-reason=suspicious-object}~1;{cs_casng:stop-reason=casing}~0;{cs_bulge:stop-reason=suspicious-bulge}~1;{cs_descr:stop-reason=fits-description}~0;{location:transit-authority}~1;{inout:inside}~0;{city:Manhattan}~1;default~0
%{cs_objcs:stop-reason=suspicious-object}~1;{cs_casng:stop-reason=casing}~0;{cs_bulge:stop-reason=suspicious-bulge}~1;{cs_descr:stop-reason=fits-description}~0;{location:housing-authority}~0;{city:Manhattan}~1;default~0
%{cs_objcs:stop-reason=suspicious-object}~1;{cs_casng:stop-reason=casing}~0;{cs_bulge:stop-reason=suspicious-bulge}~1;{cs_descr:stop-reason=fits-description}~0;{location:transit-authority}~1;{inout:inside}~0;{city:Manhattan}~1;default~0
%{cs_objcs:stop-reason=suspicious-object}~1;{cs_casng:stop-reason=casing}~0;{cs_bulge:stop-reason=suspicious-bulge}~1;{cs_descr:stop-reason=fits-description}~0;{location:transit-authority}~1;{inout:inside}~0;{city:Manhattan}~1;{ac_cgdir:circumstances=changed-direction}~0;{city:Bronx}~1;default~0
%{cs_objcs:stop-reason=suspicious-object}~1;{cs_casng:stop-reason=casing}~0;{cs_bulge:stop-reason=suspicious-bulge}~1;{location:housing-authority}~0;{cs_descr:stop-reason=fits-description}~0;{city:Manhattan}~1;default~0
%{cs_objcs:stop-reason=suspicious-object}~1;{cs_casng:stop-reason=casing}~0;{cs_bulge:stop-reason=suspicious-bulge}~1;{cs_descr:stop-reason=fits-description}~0;{cs_vcrim:stop-reason=actions-of-violent-crime}~0;{location:transit-authority}~1;{inout:inside}~0;{city:Manhattan}~1;{ac_evasv:circumstances=evasive-response}~0;{city:Bronx}~1;default~0
\begin{figure}[h!]
\textbf{Weapon prediction $(\Reg = 0.0025)$}
\vspace{0.5mm}
\scriptsize
\begin{algorithmic}
\State \bif $(stop~reason = suspicious~object)$ \bthen $yes$ \Comment{Found by 4 folds $(K=7)$}
\State \belif $(stop~reason = casing)$ \bthen $no$
\State \belif $(stop~reason = suspicious~bulge)$ \bthen $yes$
\State \belif $(stop~reason = fits~description)$ \bthen $no$
\State \belif $(location = transit~authority)$ \bthen $yes$
\State \belif $(inside~or~outside = inside)$ \bthen $no$
\State \belif $(city = Manhattan)$ \bthen $yes$
\State \belse $no$
\end{algorithmic}
\vspace{0.5mm}
\begin{algorithmic}
\State \bif $(stop~reason = suspicious~object)$ \bthen $yes$ \Comment{Found by 1 fold $(K=6)$}
\State \belif $(stop~reason = casing)$ \bthen $no$
\State \belif $(stop~reason = suspicious~bulge)$ \bthen $yes$
\State \belif $(location = housing~authority)$ \bthen $no$
\State \belif $(stop~reason = fits~description)$ \bthen $no$
\State \belif $(city = Manhattan)$ \bthen $yes$
\State \belse $no$
\end{algorithmic}
\vspace{0.5mm}
\begin{algorithmic}
\State \bif $(stop~reason = suspicious~object)$ \bthen $yes$ \Comment{Found by 1 fold $(K=6)$}
\State \belif $(stop~reason = suspicious~bulge)$ \bthen $yes$
\State \belif $(location = housing~authority)$ \bthen $no$
\State \belif $(stop~reason = fits~description)$ \bthen $no$
\State \belif $(stop~reason = casing)$ \bthen $no$
\State \belif $(city = Manhattan)$ \bthen $yes$
\State \belse $no$
\end{algorithmic}
\vspace{0.5mm}
\begin{algorithmic}
\State \bif $(stop~reason = suspicious~object)$ \bthen $yes$ \Comment{Found by 1 fold $(K=6)$}
\State \belif $(stop~reason = casing)$ \bthen $no$
\State \belif $(stop~reason = suspicious~bulge)$ \bthen $yes$
\State \belif $(stop~reason = fits~description)$ \bthen $no$
\State \belif $(location = housing~authority)$ \bthen $no$
\State \belif $(city = Manhattan)$ \bthen $yes$
\State \belse $no$
\end{algorithmic}
\vspace{0.5mm}
\begin{algorithmic}
\State \bif $(stop~reason = suspicious~object)$ \bthen $yes$ \Comment{Found by 1 fold $(K=9)$}
\State \belif $(stop~reason = casing)$ \bthen $no$
\State \belif $(stop~reason = suspicious~bulge)$ \bthen $yes$
\State \belif $(stop~reason = fits~description)$ \bthen $no$
\State \belif $(location = transit~authority)$ \bthen $yes$
\State \belif $(inside~or~outside = inside)$ \bthen $no$
\State \belif $(city = Manhattan)$ \bthen $yes$
\State \belif $(additional~circumstances = changed~direction)$ \bthen $no$
\State \belif $(city = Bronx)$ \bthen $yes$
\State \belse $no$
\end{algorithmic}
\vspace{0.5mm}
\begin{algorithmic}
\State \bif $(stop~reason = suspicious~object)$ \bthen $yes$ \Comment{Found by 1 fold $(K=10)$}
\State \belif $(stop~reason = casing)$ \bthen $no$
\State \belif $(stop~reason = suspicious~bulge)$ \bthen $yes$
\State \belif $(stop~reason = fits~description)$ \bthen $no$
\State \belif $(stop~reason = actions~of~violent~crime)$ \bthen $no$
\State \belif $(location = transit~authority)$ \bthen $yes$
\State \belif $(inside~or~outside = inside)$ \bthen $no$
\State \belif $(city = Manhattan)$ \bthen $yes$
\State \belif $(additional~circumstances = evasive~response)$ \bthen $no$
\State \belif $(city = Bronx)$ \bthen $yes$
\State \belse $no$
\end{algorithmic}
\vspace{0.5mm}
\begin{algorithmic}
\State \bif $(stop~reason = drug~transaction)$ \bthen $no$ \Comment{Found by 1 fold $(K=8)$}
\State \belif $(stop~reason = suspicious~bulge)$ \bthen $yes$
\State \belif $(stop~reason = suspicious~object)$ \bthen $yes$
\State \belif $(location = housing~authority)$ \bthen $no$
\State \belif $(stop~reason = fits~description)$ \bthen $no$
\State \belif $(stop~reason = casing)$ \bthen $no$
\State \belif $(city = Manhattan)$ \bthen $yes$
\State \belif $(city = Bronx)$ \bthen $yes$
\State \belse $no$
\end{algorithmic}
\caption{Example optimal rule lists for the NYCLU stop-and-frisk dataset~${\Reg = 0.0025}$.
%found by CORELS with regularization parameter, across 10 cross-validation folds.
}
\label{fig:weapon-rule-list-0025}
\end{figure}
